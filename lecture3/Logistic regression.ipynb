{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBOTCYcmMNIY"
      },
      "source": [
        "# Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibj59liGMNIa"
      },
      "source": [
        "## 2) Logistic Regression (classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPwK4cTkMNIb"
      },
      "source": [
        "### 1-1) Logistic Regression from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGerpU9ZMNIb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC_fAeg0MNIc"
      },
      "source": [
        "# Step 1. Data Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUVyRdBbMNIc"
      },
      "source": [
        "## data ( height and weight of  adults and children)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsejTN5_MNId"
      },
      "outputs": [],
      "source": [
        "# The number of data to be created\n",
        "m = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJO2oxSEMNId"
      },
      "outputs": [],
      "source": [
        "adult_height = np.random.normal(175, 5, [m, 1])\n",
        "adult_weight = np.random.normal(70, 5, [m, 1])\n",
        "\n",
        "adult_dataset = np.concatenate( (adult_weight, adult_height) , axis = 1)\n",
        "\n",
        "print(adult_dataset.shape)\n",
        "print(adult_dataset[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE6SxrLQMNIe"
      },
      "outputs": [],
      "source": [
        "child_height = np.random.normal(120, 5, [m, 1])\n",
        "child_weight = np.random.normal(30, 5, [m, 1])\n",
        "\n",
        "child_dataset = np.concatenate( (child_weight, child_height) , axis = 1)\n",
        "\n",
        "print(child_dataset.shape)\n",
        "print(child_dataset[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXDw1-MwMNIe"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "ax1.scatter(adult_dataset[:,0], adult_dataset[:,1], c=np.array([(1, 1, 0)]))\n",
        "ax1.scatter(child_dataset[:,0], child_dataset[:,1], c=np.array([(0, 1, 0)]))\n",
        "plt.title(\"The distribution of created dataset \")\n",
        "plt.xlabel(\"height x2\")\n",
        "plt.ylabel(\"weight x1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FdTctmtMNIf"
      },
      "source": [
        "## Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GRCnkQQMNIf"
      },
      "outputs": [],
      "source": [
        "# 각각의 클레스에 대한 레이블을 만들어줍니다.\n",
        "# adult는 1로, child는 0으로 지정합니다.\n",
        "# binary classification은 내가 찾는 클래스(1)이냐 아니냐(0)를 분류합니다.\n",
        "# 즉 우리가 학습시킬 모델은 성인과 성인이 아닌 데이터를 분류하는 모델입니다.\n",
        "\n",
        "adult_label = np.ones( shape=[m, 1] )\n",
        "child_label = np.zeros( shape=[m, 1] )\n",
        "label = np.concatenate( (adult_label, child_label) )\n",
        "print('label의 shape' , label.shape)\n",
        "print(label[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBG5fbD0MNIf"
      },
      "source": [
        "## Data + Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE_yCaXbMNIg"
      },
      "outputs": [],
      "source": [
        "total_dataset = np.concatenate((adult_dataset , child_dataset))\n",
        "total_dataset = np.concatenate( (total_dataset, label), axis = 1  )\n",
        "\n",
        "np.random.shuffle(total_dataset) # Shuffle dataset\n",
        "print(total_dataset[:10])\n",
        "print(total_dataset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP9ZdJgLMNIg"
      },
      "source": [
        "## simple scaling of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnCUy1tMMNIg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(total_dataset[:,:2])\n",
        "print(scaler.mean_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKACvjtKMNIg"
      },
      "outputs": [],
      "source": [
        "total_dataset[:,:2] = scaler.transform(total_dataset[:,:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea-koN6MMNIh"
      },
      "outputs": [],
      "source": [
        "total_dataset.shape\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "color = [(1*i, 1, 0) for i in total_dataset[:,2] ]\n",
        "ax1.scatter(total_dataset[:,0], total_dataset[:,1], c = color)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm1ZgPv6MNIh"
      },
      "source": [
        "# Step 2. Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGemLtgRMNIh"
      },
      "outputs": [],
      "source": [
        "def linear(x, w, b):\n",
        "    pred = np.matmul(x, w.T) + b\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOwhfx6hMNIh"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv6Po9qfMNIh"
      },
      "outputs": [],
      "source": [
        "def hypothesis(x,w,b):\n",
        "    return sigmoid(linear(x, w, b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlPVXwLFMNIi"
      },
      "outputs": [],
      "source": [
        "def cost(x, w, b, y):\n",
        "    loss = -y*linear(x, w, b) + np.log(1 + np.exp(linear(x, w, b))) \n",
        "    #-ylog(h(x))-(1-y)log(1-h(x)) =  -y*(wx+b) + log(1+exp(wx+b))\n",
        "    cost = (1/m)*np.sum(loss) # mean of losses\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbR1-offMNIi"
      },
      "outputs": [],
      "source": [
        "def derivative(x, w, b, y):\n",
        "    dw = (1/m)* np.sum( x*(hypothesis(x, w, b)-y) , axis = 0) # 1 x w_dim\n",
        "    # (1/m)*x(h(x)-y)\n",
        "    db = (1/m)* np.sum( hypothesis(x, w, b)-y, axis = 0 )\n",
        "    # (1/m)*(h(x)-y)\n",
        "    return dw, db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB7mtjHcMNIi"
      },
      "outputs": [],
      "source": [
        "def update(x, w, b, y, alpha):\n",
        "    w = w - alpha*(derivative(x, w, b, y)[0]) # w := w - alpha * dw\n",
        "    b = b - alpha*(derivative(x, w, b, y)[1]) # b := b - alpha * db\n",
        "    return w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnnN1fPVMNIi"
      },
      "source": [
        "# Step 3. Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96UtVeMzMNIi"
      },
      "outputs": [],
      "source": [
        "# initialization of weights and bias\n",
        "w = np.array([[3.0, -3.0]])\n",
        "b = -1.345\n",
        "\n",
        "x = total_dataset[:, :2] # x1, x2\n",
        "y = total_dataset[:, 2:3] # label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nL-8MYhMNIi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlC0084bMNIi"
      },
      "source": [
        "## 아래 두 개 cell을 반복하여 실행하며, 선형 분류기의 위치 변화를 관찰해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97AKo7IhMNIj"
      },
      "outputs": [],
      "source": [
        "def visualize(w, b):\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(111)\n",
        "    color = [(1*i, 1, 0) for i in total_dataset[:,2] ]\n",
        "    ax1.scatter(total_dataset[:,0], total_dataset[:,1], c = color)\n",
        "\n",
        "    p1 = np.array([0, -b/w[0, 1]])\n",
        "    p2 = np.array([-b[0]/w[0, 0], 0]) # b has the shape as [1]\n",
        "    coefficients = np.polyfit([p1[0], p2[0]], [p1[1][0], p2[1]], 1)  \n",
        "    polynomial = np.poly1d(coefficients)\n",
        "    x_axis = np.linspace(-2.0, 2.0)\n",
        "    y_axis = polynomial(x_axis)\n",
        "    ax1.set_ylim(-2.0, 2.0)\n",
        "    ax1.plot(x_axis, y_axis)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zzMMXsfMNIj"
      },
      "outputs": [],
      "source": [
        "for i in range(3001):\n",
        "    w, b = update(x, w, b, y, alpha=0.005)\n",
        "    if i%500 == 0:\n",
        "      print('cost = ', cost(x, w, b, y))\n",
        "      visualize(w, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBEt5CKqMNIj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "preds = hypothesis(x,w,b)\n",
        "preds = (preds>0.5).astype(np.int32)\n",
        "print(preds[:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "id": "QenHR17cPrDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"정확도 = \", accuracy_score(np.squeeze(preds), np.squeeze(y)))"
      ],
      "metadata": {
        "id": "Ea4SePZyO9P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 사용"
      ],
      "metadata": {
        "id": "owCkQMRuMjK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "LR.fit(x,y)"
      ],
      "metadata": {
        "id": "dsBUDyaEMlme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR.predict(x)"
      ],
      "metadata": {
        "id": "vcc9K5SuQGpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrCNAj1XMNIj"
      },
      "source": [
        "# 이런 문제는 어떨까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVkQOfGTMNIj"
      },
      "outputs": [],
      "source": [
        "# 임의의 클래스 A와 클래스 B를 생성함.\n",
        "m = 200\n",
        "class_A = np.random.normal(0, 1, [m, 2])\n",
        "label_A = np.ones([m, 1])\n",
        "\n",
        "class_B_x = np.random.normal(0, 2, [m, 1])\n",
        "class_B_y = 0.5*class_B_x**2 - 3\n",
        "\n",
        "class_B = np.concatenate([class_B_x, class_B_y], axis = 1)\n",
        "label_B = np.zeros([m, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipx5-d_wMNIj"
      },
      "outputs": [],
      "source": [
        "#데이터 분포를 볼까요?\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ax1.set_title('nonlinear distribution')\n",
        "ax1.set_xlabel('x1')\n",
        "ax1.set_ylabel('x2')\n",
        "\n",
        "ax1.set_xlim([-4,4])\n",
        "ax1.set_ylim([-4,4])\n",
        "\n",
        "ax1.scatter(class_A[:,0], class_A[:,1], c='red')\n",
        "\n",
        "ax1.scatter(class_B[:,0], class_B[:,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Keql2JM9MNIk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다른 종류의 분류"
      ],
      "metadata": {
        "id": "yBR4Y3CMMQ0i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3r6S056MNIk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SW6QQbXMNIk"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTqLtHtIMNIk"
      },
      "outputs": [],
      "source": [
        "#데이터의 shape을 볼까요?\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-MR_hN7MNIk"
      },
      "outputs": [],
      "source": [
        "# 60000개 중 첫번째 데이터를 봅시다.\n",
        "img = x_train[0]\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM2NhVGTMNIl"
      },
      "outputs": [],
      "source": [
        "# 값도 출력해봅시다.\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzdfeaBfMNIl"
      },
      "outputs": [],
      "source": [
        "# 값도 출력해봅시다.\n",
        "vectorized = np.reshape(img, [28*28])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alcqc_sNMNIl"
      },
      "outputs": [],
      "source": [
        "vectorized.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrgOczQrMNIl"
      },
      "outputs": [],
      "source": [
        "#이런 데이터도 잘 분류될 수 있을까?\n",
        "print(vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqSPmfd-MNIl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Logistic regression.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}