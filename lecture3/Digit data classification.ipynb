{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Scb4NQe2zCPP"
   },
   "source": [
    "# **Digit 데이터를 이용한 <span style=\"color:darkgreen\">뉴럴네트워크</span> 문제**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyVZUOyPZlkN"
   },
   "source": [
    "> **<span style=\"color:red\">다음 문항을 풀기 전에 </span>아래 코드를 실행하시오.**<br>\n",
    "> 반드시 코드와 주석을 읽고 문제를 푸시오. <br>\n",
    "> 출력된 데이터 설명을 **반드시** 읽고 문제를 푸시오.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1628227988840,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "fiSDKfH9abY7",
    "outputId": "880b1691-c829-491c-ff4f-4c8a6aa8b926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "x = digits.images # 인풋으로 사용할 데이터.\n",
    "y = digits.target # 아웃풋으로 사용할 데이터.\n",
    "\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heKPp9gV0che"
   },
   "source": [
    "# Q1. 다음 조건에 맞추어 데이터를 분할하시오.\n",
    "---------------------------\n",
    "* 변수명 규칙 : x_train, x_test, y_train, y_test\n",
    "* train : test = 9 : 1\n",
    "* y의 클래스가 골고루 분할이 되도록 stratify하게 분할한다.\n",
    "* random state, seed등은 2021로 고정.\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1628227989118,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "UaW-TZha1QFX"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "x_train, x_test, y_train, y_test = tts(x, y, test_size = 0.1, stratify=y, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oviV2HIh1ePP"
   },
   "source": [
    "# Q2. 모든 x들을 min-max scaling 하시오.\n",
    "---------------------------\n",
    "* 모든 트레이닝 규칙은 트레이닝 셋을 이용하여 찾아낸다.\n",
    "* 제대로 스케일링 되었는지, 결과도 확인한다.\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628227989118,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "xk5q8Ema1ePR"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "max_ = x_train.max()\n",
    "min_ = x_test.min()\n",
    "\n",
    "x_train = ( x_train - min_ )/( max_ - min_ )\n",
    "x_test =( x_test - min_ )/( max_ - min_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnpStAuj2Gmu"
   },
   "source": [
    "# Q3. 실행할 때마다 트레이닝셋의 이미지 하나를 랜덤하게 시각화 하는 코드를 작성하시오.\n",
    "--------------------\n",
    "* 그 이미지가 어떤 클래스인지도 같이 출력하는 코드를 작성하시오.\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1628227989425,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "q_24UYjO2aju",
    "outputId": "f3701500-b768-4f3b-dd09-d4a1e18eb9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 이미지는 5입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "id = np.random.randint(0, len(x_train))\n",
    "\n",
    "print(f\"아래 이미지는 {y_train[id]}입니다.\")\n",
    "plt.imshow(x_train[id], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tf9hpt_21LC"
   },
   "source": [
    "# Q4. y들을 원핫인코딩 하시오.\n",
    "----------------\n",
    "* 모든 전처리 규칙은 트레이닝셋을 이용하여 찾는다.\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628227989426,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "2ujn3mJa3ISt"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_ca = len(set(y_train))\n",
    "\n",
    "y_train = to_categorical(y_train, num_ca)\n",
    "y_test = to_categorical(y_test, num_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNfKuylW4iuv"
   },
   "source": [
    "# Q5. 다음 조건에 맞추어 뉴럴넷을 모델링 하시오.\n",
    "------------------------------\n",
    "* model1 에 모델을 선언해둔다.\n",
    "* 컴파일까지 마친다.\n",
    "    - 모니터링용 지표로 accuracy를 둔다.\n",
    "* 모델 구조는 아래와 같다.\n",
    "    - x의 모양에 맞는 적절한 인풋레이어\n",
    "    - Fully connected layer로 연결하기 위한 모양변환 레이어\n",
    "    - Fully connected layer, 64개 노드, swish\n",
    "    - Fully connected layer, 64개 노드, swish\n",
    "    - 적절한 아웃풋 레이어\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628227989426,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "gP5zJDHK5GT2",
    "outputId": "2e4ac0fa-c34c-44b4-c21f-a8f3f1053682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 8)]            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 8,970\n",
      "Trainable params: 8,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "il = keras.layers.Input(shape=(8,8))\n",
    "hl = keras.layers.Flatten()(il)\n",
    "hl = keras.layers.Dense(64, 'swish')(hl)\n",
    "hl = keras.layers.Dense(64, 'swish')(hl)\n",
    "ol = keras.layers.Dense(10, 'softmax')(hl)\n",
    "\n",
    "model1 = keras.models.Model(il, ol)\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nBHkekK5lUF"
   },
   "source": [
    "# Q6. 다음 조건에 맞추어 model1을 얼리스토핑을 이용하여 학습시키시오.\n",
    "--------------\n",
    "* epochs = 10000\n",
    "* batch size는 256\n",
    "* 10번 연속 개선이 없으면 stop\n",
    "    - loss가 유지만 되어도 개선됨으로 간주\n",
    "* 얼리스토핑시, 가장 성능이 좋았던 가중치로 복구.\n",
    "* 벨리데이션 셋은, 트레이닝 셋의 15%를 사용.\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4339,
     "status": "ok",
     "timestamp": 1628227993762,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "kzT6ssUq59GI",
    "outputId": "ae8a1d5b-35bc-4774-ae1f-1b12dfab39c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "6/6 [==============================] - 1s 36ms/step - loss: 2.3193 - accuracy: 0.0677 - val_loss: 2.2586 - val_accuracy: 0.1811\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2342 - accuracy: 0.2817 - val_loss: 2.1878 - val_accuracy: 0.4362\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1550 - accuracy: 0.4927 - val_loss: 2.1092 - val_accuracy: 0.5844\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.0665 - accuracy: 0.6397 - val_loss: 2.0128 - val_accuracy: 0.7037\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9600 - accuracy: 0.7220 - val_loss: 1.8945 - val_accuracy: 0.7366\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8298 - accuracy: 0.7351 - val_loss: 1.7481 - val_accuracy: 0.7572\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6694 - accuracy: 0.7613 - val_loss: 1.5702 - val_accuracy: 0.7654\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4774 - accuracy: 0.7962 - val_loss: 1.3613 - val_accuracy: 0.7819\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2614 - accuracy: 0.8319 - val_loss: 1.1392 - val_accuracy: 0.8107\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0362 - accuracy: 0.8515 - val_loss: 0.9201 - val_accuracy: 0.8560\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8272 - accuracy: 0.8705 - val_loss: 0.7270 - val_accuracy: 0.8560\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6559 - accuracy: 0.8806 - val_loss: 0.5865 - val_accuracy: 0.8642\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.8937 - val_loss: 0.4765 - val_accuracy: 0.8889\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.9010 - val_loss: 0.4091 - val_accuracy: 0.8889\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.9134 - val_loss: 0.3479 - val_accuracy: 0.9095\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3213 - accuracy: 0.9192 - val_loss: 0.3196 - val_accuracy: 0.9177\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2804 - accuracy: 0.9272 - val_loss: 0.2751 - val_accuracy: 0.9218\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2533 - accuracy: 0.9316 - val_loss: 0.2598 - val_accuracy: 0.9300\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2289 - accuracy: 0.9410 - val_loss: 0.2368 - val_accuracy: 0.9300\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2110 - accuracy: 0.9461 - val_loss: 0.2273 - val_accuracy: 0.9342\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1976 - accuracy: 0.9483 - val_loss: 0.2093 - val_accuracy: 0.9342\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1805 - accuracy: 0.9520 - val_loss: 0.1966 - val_accuracy: 0.9342\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1714 - accuracy: 0.9549 - val_loss: 0.1926 - val_accuracy: 0.9424\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1605 - accuracy: 0.9607 - val_loss: 0.1781 - val_accuracy: 0.9465\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1534 - accuracy: 0.9614 - val_loss: 0.1764 - val_accuracy: 0.9383\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.9665 - val_loss: 0.1681 - val_accuracy: 0.9506\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1363 - accuracy: 0.9731 - val_loss: 0.1643 - val_accuracy: 0.9547\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.9716 - val_loss: 0.1593 - val_accuracy: 0.9506\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1254 - accuracy: 0.9716 - val_loss: 0.1520 - val_accuracy: 0.9588\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.9789 - val_loss: 0.1519 - val_accuracy: 0.9588\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.9782 - val_loss: 0.1462 - val_accuracy: 0.9588\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9767 - val_loss: 0.1432 - val_accuracy: 0.9588\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9789 - val_loss: 0.1400 - val_accuracy: 0.9588\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.9782 - val_loss: 0.1428 - val_accuracy: 0.9547\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9811 - val_loss: 0.1390 - val_accuracy: 0.9588\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9796 - val_loss: 0.1320 - val_accuracy: 0.9630\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9803 - val_loss: 0.1362 - val_accuracy: 0.9630\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0884 - accuracy: 0.9825 - val_loss: 0.1275 - val_accuracy: 0.9671\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9803 - val_loss: 0.1313 - val_accuracy: 0.9588\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9825 - val_loss: 0.1230 - val_accuracy: 0.9630\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9825 - val_loss: 0.1286 - val_accuracy: 0.9588\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9833 - val_loss: 0.1203 - val_accuracy: 0.9630\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9840 - val_loss: 0.1283 - val_accuracy: 0.9671\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9840 - val_loss: 0.1205 - val_accuracy: 0.9630\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0732 - accuracy: 0.9854 - val_loss: 0.1193 - val_accuracy: 0.9712\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.9862 - val_loss: 0.1263 - val_accuracy: 0.9588\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9840 - val_loss: 0.1126 - val_accuracy: 0.9671\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0688 - accuracy: 0.9876 - val_loss: 0.1186 - val_accuracy: 0.9588\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0650 - accuracy: 0.9847 - val_loss: 0.1152 - val_accuracy: 0.9712\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0631 - accuracy: 0.9869 - val_loss: 0.1119 - val_accuracy: 0.9630\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.9847 - val_loss: 0.1153 - val_accuracy: 0.9671\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9876 - val_loss: 0.1131 - val_accuracy: 0.9712\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9884 - val_loss: 0.1184 - val_accuracy: 0.9671\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9891 - val_loss: 0.1106 - val_accuracy: 0.9630\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9891 - val_loss: 0.1149 - val_accuracy: 0.9671\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0532 - accuracy: 0.9891 - val_loss: 0.1115 - val_accuracy: 0.9671\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9920 - val_loss: 0.1099 - val_accuracy: 0.9671\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9920 - val_loss: 0.1149 - val_accuracy: 0.9671\n",
      "Epoch 59/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0508 - accuracy: 0.9905 - val_loss: 0.1100 - val_accuracy: 0.9712\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9905 - val_loss: 0.1089 - val_accuracy: 0.9712\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9942 - val_loss: 0.1128 - val_accuracy: 0.9712\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0481 - accuracy: 0.9913 - val_loss: 0.1116 - val_accuracy: 0.9671\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9927 - val_loss: 0.1070 - val_accuracy: 0.9712\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9905 - val_loss: 0.1165 - val_accuracy: 0.9671\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9949 - val_loss: 0.1063 - val_accuracy: 0.9712\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0427 - accuracy: 0.9949 - val_loss: 0.1131 - val_accuracy: 0.9671\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9942 - val_loss: 0.1069 - val_accuracy: 0.9671\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0400 - accuracy: 0.9949 - val_loss: 0.1073 - val_accuracy: 0.9671\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9942 - val_loss: 0.1102 - val_accuracy: 0.9671\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0380 - accuracy: 0.9964 - val_loss: 0.1040 - val_accuracy: 0.9671\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0380 - accuracy: 0.9956 - val_loss: 0.1089 - val_accuracy: 0.9671\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9964 - val_loss: 0.1058 - val_accuracy: 0.9712\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9964 - val_loss: 0.1076 - val_accuracy: 0.9712\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9956 - val_loss: 0.1034 - val_accuracy: 0.9671\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9971 - val_loss: 0.1081 - val_accuracy: 0.9712\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9964 - val_loss: 0.1018 - val_accuracy: 0.9753\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9964 - val_loss: 0.1072 - val_accuracy: 0.9671\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9956 - val_loss: 0.1068 - val_accuracy: 0.9712\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9971 - val_loss: 0.1037 - val_accuracy: 0.9671\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9978 - val_loss: 0.1065 - val_accuracy: 0.9671\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9964 - val_loss: 0.1038 - val_accuracy: 0.9712\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9964 - val_loss: 0.1101 - val_accuracy: 0.9671\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9971 - val_loss: 0.1053 - val_accuracy: 0.9712\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9964 - val_loss: 0.1116 - val_accuracy: 0.9671\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9956 - val_loss: 0.1032 - val_accuracy: 0.9671\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9978 - val_loss: 0.1070 - val_accuracy: 0.9712\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00086: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe128831750>"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   min_delta=0, patience=10,\n",
    "                   verbose=1, restore_best_weights=True)\n",
    "\n",
    "model1.fit(x_train, y_train, epochs=10000, batch_size=256, validation_split=0.15,\n",
    "           callbacks=[es], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34VQNpKS6lsg"
   },
   "source": [
    "# Q7. 다음 조건에 맞추어 뉴럴넷을 모델링 하시오.\n",
    "------------------------------\n",
    "* model2 에 모델을 선언해둔다.\n",
    "* 컴파일까지 마친다.\n",
    "    - 모니터링용 지표로 accuracy를 둔다.\n",
    "* 모델 구조는 아래와 같다.\n",
    "    - x의 모양에 맞는 적절한 인풋레이어\n",
    "    - Fully connected layer로 연결하기 위한 모양변환 레이어\n",
    "    - Fully connected layer, 128개 노드, swish\n",
    "    - Batch normalization\n",
    "    - drop out : drop rate 25%\n",
    "    - Fully connected layer, 128개 노드, swish\n",
    "    - Batch normalization\n",
    "    - drop out : drop rate 25%\n",
    "    - 적절한 아웃풋 레이어\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1426,
     "status": "ok",
     "timestamp": 1628227995186,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "anm52rbJ6lsg",
    "outputId": "99e6dfb7-4613-40f4-8585-628febae7353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 8, 8)]            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 27,146\n",
      "Trainable params: 26,634\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "il = keras.layers.Input(shape=(8,8))\n",
    "hl = keras.layers.Flatten()(il)\n",
    "hl = keras.layers.Dense(128, 'swish')(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(0.25)(hl)\n",
    "hl = keras.layers.Dense(128, 'swish')(hl)\n",
    "hl = keras.layers.BatchNormalization()(hl)\n",
    "hl = keras.layers.Dropout(0.25)(hl)\n",
    "ol = keras.layers.Dense(10, 'softmax')(hl)\n",
    "\n",
    "model2 = keras.models.Model(il, ol)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXoVesOe8cuR"
   },
   "source": [
    "# Q8. 다음 조건에 맞추어 model2을 얼리스토핑을 이용하여 학습시키시오.\n",
    "--------------\n",
    "* epochs = 10000\n",
    "* batch size는 256\n",
    "* 10번 연속 개선이 없으면 stop\n",
    "    - loss가 유지만 되어도 개선됨으로 간주\n",
    "* 얼리스토핑시, 가장 성능이 좋았던 가중치로 복구.\n",
    "* 벨리데이션 셋은, 트레이닝 셋의 15%를 사용.\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6800,
     "status": "ok",
     "timestamp": 1628228001983,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "vkLRUsyV8cuT",
    "outputId": "f5df10cf-c074-4545-9a68-c1bd1b8c1ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "6/6 [==============================] - 1s 42ms/step - loss: 2.7400 - accuracy: 0.2016 - val_loss: 2.1702 - val_accuracy: 0.3786\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2324 - accuracy: 0.6019 - val_loss: 2.0442 - val_accuracy: 0.6584\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7179 - accuracy: 0.7656 - val_loss: 1.9445 - val_accuracy: 0.7613\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4887 - accuracy: 0.8552 - val_loss: 1.8696 - val_accuracy: 0.7984\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3649 - accuracy: 0.8785 - val_loss: 1.8121 - val_accuracy: 0.7860\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3077 - accuracy: 0.9178 - val_loss: 1.7637 - val_accuracy: 0.7531\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2585 - accuracy: 0.9229 - val_loss: 1.7190 - val_accuracy: 0.7449\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2459 - accuracy: 0.9265 - val_loss: 1.6793 - val_accuracy: 0.7325\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2043 - accuracy: 0.9469 - val_loss: 1.6409 - val_accuracy: 0.7202\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1974 - accuracy: 0.9483 - val_loss: 1.6025 - val_accuracy: 0.7202\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1875 - accuracy: 0.9483 - val_loss: 1.5649 - val_accuracy: 0.7243\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1765 - accuracy: 0.9527 - val_loss: 1.5280 - val_accuracy: 0.7284\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1581 - accuracy: 0.9585 - val_loss: 1.4902 - val_accuracy: 0.7407\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1377 - accuracy: 0.9687 - val_loss: 1.4518 - val_accuracy: 0.7490\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1376 - accuracy: 0.9643 - val_loss: 1.4118 - val_accuracy: 0.7654\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1275 - accuracy: 0.9687 - val_loss: 1.3703 - val_accuracy: 0.7778\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1236 - accuracy: 0.9680 - val_loss: 1.3320 - val_accuracy: 0.7737\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1075 - accuracy: 0.9760 - val_loss: 1.2914 - val_accuracy: 0.7860\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1179 - accuracy: 0.9702 - val_loss: 1.2503 - val_accuracy: 0.7984\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1054 - accuracy: 0.9723 - val_loss: 1.2110 - val_accuracy: 0.7942\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1024 - accuracy: 0.9745 - val_loss: 1.1709 - val_accuracy: 0.8066\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1021 - accuracy: 0.9723 - val_loss: 1.1317 - val_accuracy: 0.8107\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0873 - accuracy: 0.9803 - val_loss: 1.0911 - val_accuracy: 0.8107\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0915 - accuracy: 0.9745 - val_loss: 1.0502 - val_accuracy: 0.8230\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9745 - val_loss: 1.0083 - val_accuracy: 0.8354\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0905 - accuracy: 0.9760 - val_loss: 0.9641 - val_accuracy: 0.8560\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0733 - accuracy: 0.9854 - val_loss: 0.9220 - val_accuracy: 0.8642\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0765 - accuracy: 0.9847 - val_loss: 0.8807 - val_accuracy: 0.8807\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0677 - accuracy: 0.9862 - val_loss: 0.8429 - val_accuracy: 0.8889\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0709 - accuracy: 0.9869 - val_loss: 0.8074 - val_accuracy: 0.8889\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9753 - val_loss: 0.7734 - val_accuracy: 0.8889\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.9833 - val_loss: 0.7365 - val_accuracy: 0.8930\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0596 - accuracy: 0.9876 - val_loss: 0.6964 - val_accuracy: 0.8930\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0609 - accuracy: 0.9898 - val_loss: 0.6580 - val_accuracy: 0.9012\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.6204 - val_accuracy: 0.9053\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0589 - accuracy: 0.9854 - val_loss: 0.5838 - val_accuracy: 0.9218\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0526 - accuracy: 0.9920 - val_loss: 0.5502 - val_accuracy: 0.9300\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0643 - accuracy: 0.9840 - val_loss: 0.5211 - val_accuracy: 0.9300\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0519 - accuracy: 0.9862 - val_loss: 0.4906 - val_accuracy: 0.9383\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0531 - accuracy: 0.9898 - val_loss: 0.4595 - val_accuracy: 0.9547\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0547 - accuracy: 0.9884 - val_loss: 0.4324 - val_accuracy: 0.9588\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 0.9891 - val_loss: 0.4058 - val_accuracy: 0.9588\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 0.9854 - val_loss: 0.3812 - val_accuracy: 0.9588\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0453 - accuracy: 0.9927 - val_loss: 0.3565 - val_accuracy: 0.9588\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0472 - accuracy: 0.9840 - val_loss: 0.3324 - val_accuracy: 0.9671\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0426 - accuracy: 0.9927 - val_loss: 0.3123 - val_accuracy: 0.9712\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9927 - val_loss: 0.2914 - val_accuracy: 0.9712\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0403 - accuracy: 0.9920 - val_loss: 0.2709 - val_accuracy: 0.9671\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.9942 - val_loss: 0.2534 - val_accuracy: 0.9671\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0428 - accuracy: 0.9884 - val_loss: 0.2371 - val_accuracy: 0.9671\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9920 - val_loss: 0.2235 - val_accuracy: 0.9671\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 0.9942 - val_loss: 0.2103 - val_accuracy: 0.9671\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9942 - val_loss: 0.1980 - val_accuracy: 0.9712\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9949 - val_loss: 0.1847 - val_accuracy: 0.9712\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0338 - accuracy: 0.9956 - val_loss: 0.1736 - val_accuracy: 0.9712\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.9891 - val_loss: 0.1630 - val_accuracy: 0.9671\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9942 - val_loss: 0.1539 - val_accuracy: 0.9671\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9949 - val_loss: 0.1448 - val_accuracy: 0.9671\n",
      "Epoch 59/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9964 - val_loss: 0.1370 - val_accuracy: 0.9671\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0401 - accuracy: 0.9913 - val_loss: 0.1294 - val_accuracy: 0.9671\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0331 - accuracy: 0.9949 - val_loss: 0.1230 - val_accuracy: 0.9671\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.1169 - val_accuracy: 0.9671\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9934 - val_loss: 0.1114 - val_accuracy: 0.9630\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9920 - val_loss: 0.1082 - val_accuracy: 0.9712\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.9934 - val_loss: 0.1074 - val_accuracy: 0.9712\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9956 - val_loss: 0.1041 - val_accuracy: 0.9712\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0333 - accuracy: 0.9942 - val_loss: 0.0988 - val_accuracy: 0.9753\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 0.9956 - val_loss: 0.0955 - val_accuracy: 0.9753\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0330 - accuracy: 0.9927 - val_loss: 0.0931 - val_accuracy: 0.9712\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9934 - val_loss: 0.0914 - val_accuracy: 0.9712\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9956 - val_loss: 0.0899 - val_accuracy: 0.9712\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9978 - val_loss: 0.0867 - val_accuracy: 0.9712\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9964 - val_loss: 0.0831 - val_accuracy: 0.9712\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 0.0820 - val_accuracy: 0.9712\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0195 - accuracy: 0.9956 - val_loss: 0.0811 - val_accuracy: 0.9712\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9942 - val_loss: 0.0801 - val_accuracy: 0.9712\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9934 - val_loss: 0.0784 - val_accuracy: 0.9753\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9978 - val_loss: 0.0766 - val_accuracy: 0.9753\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9964 - val_loss: 0.0751 - val_accuracy: 0.9753\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9956 - val_loss: 0.0752 - val_accuracy: 0.9753\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9971 - val_loss: 0.0739 - val_accuracy: 0.9753\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 0.9927 - val_loss: 0.0724 - val_accuracy: 0.9753\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0197 - accuracy: 0.9971 - val_loss: 0.0716 - val_accuracy: 0.9753\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9964 - val_loss: 0.0708 - val_accuracy: 0.9753\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0164 - accuracy: 0.9978 - val_loss: 0.0710 - val_accuracy: 0.9753\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9964 - val_loss: 0.0702 - val_accuracy: 0.9753\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 0.0694 - val_accuracy: 0.9753\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.0682 - val_accuracy: 0.9753\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0182 - accuracy: 0.9978 - val_loss: 0.0674 - val_accuracy: 0.9753\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 0.0671 - val_accuracy: 0.9753\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9978 - val_loss: 0.0674 - val_accuracy: 0.9753\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.0672 - val_accuracy: 0.9753\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9985 - val_loss: 0.0662 - val_accuracy: 0.9753\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.9971 - val_loss: 0.0659 - val_accuracy: 0.9794\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9794\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9964 - val_loss: 0.0674 - val_accuracy: 0.9794\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9978 - val_loss: 0.0685 - val_accuracy: 0.9794\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 0.9964 - val_loss: 0.0682 - val_accuracy: 0.9794\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 0.9964 - val_loss: 0.0681 - val_accuracy: 0.9753\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.0679 - val_accuracy: 0.9753\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9964 - val_loss: 0.0660 - val_accuracy: 0.9753\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9978 - val_loss: 0.0662 - val_accuracy: 0.9753\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9985 - val_loss: 0.0677 - val_accuracy: 0.9753\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0153 - accuracy: 0.9978 - val_loss: 0.0686 - val_accuracy: 0.9753\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00104: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe12964a310>"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   min_delta=0, patience=10,\n",
    "                   verbose=1, restore_best_weights=True)\n",
    "\n",
    "model2.fit(x_train, y_train, epochs=10000, batch_size=256, validation_split=0.15,\n",
    "           callbacks=[es], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFGc2QHe8kfH"
   },
   "source": [
    "# Q9. 테스트셋 위에서 두 모델을 비교하시오.\n",
    "---------------------------------\n",
    "* 두 모델의 accuracy를 출력한다.\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1628228039026,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "f_jhJafb8qGW",
    "outputId": "200dbec7-304c-40d0-9d2d-813ad8337d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9611\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.10789534449577332, 0.9611111283302307],\n",
       " [0.07070343941450119, 0.9888888597488403])"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "model1.evaluate(x_test, y_test), model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH0Ru9Ey9E5k"
   },
   "source": [
    "# Q10. 성능이 더 좋은 모델을 이용해, 테스트 이미지를 시각화 하시오.\n",
    "----------------------------\n",
    "* 랜덤하게 테스트 이미지 한장을 시각화 한다.\n",
    "* 그 이미지가 실제 어떤 클래스인지 출력한다.\n",
    "    - 원핫 인코딩 된 정보를 출력하지 않는다.\n",
    "* 모델이 예측한 클래스도 같이 출력한다.\n",
    "    - 확률 정보를 출력하지 않는다.\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628228301960,
     "user": {
      "displayName": "Rayleigh Kim",
      "photoUrl": "",
      "userId": "07970978477328976416"
     },
     "user_tz": -540
    },
    "id": "_ONJOesl9VOo",
    "outputId": "4f2b7d10-5cd7-4bca-e559-0c6759796f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 이미지는 : 1 입니다.\n",
      "모델의 예측은 : 1 입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################\n",
    "## your code here ##\n",
    "####################\n",
    "\n",
    "id = id = np.random.randint(0, len(x_test))\n",
    "\n",
    "y_pred = model2.predict(x_test[id:id+1])\n",
    "\n",
    "print(f\"아래 이미지는 : {y_test[id].argmax()} 입니다.\")\n",
    "print(f\"모델의 예측은 : {y_pred.argmax()} 입니다.\")\n",
    "plt.imshow(x_test[id], cmap='Greys')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNTpj3SM/frlweNhjpPel3g",
   "collapsed_sections": [],
   "name": "(sol)Problem_04(딥러닝).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
