{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "2.Image_processing.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnhk37C4xwlv"
      },
      "source": [
        "#github repository sync in google colab\n",
        "import os\n",
        "try:\n",
        "  # Colab only\n",
        "  !git clone https://github.com/hukim1112/MLDL.git\n",
        "  os.chdir('/content/MLDL/lecture5')      \n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tHaxTLFxwly"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H-8WpYUxwlz"
      },
      "source": [
        "***modify image by drawing via cv2***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Z7b31Axwl0"
      },
      "source": [
        "# ***Traditional Image Processing by cv2***\n",
        "- transform (translation, rotation, resizing, flipping and cropping)\n",
        "- pixel arithmetics\n",
        "- color channel decomposition\n",
        "- most of them are using warpAffine, because some transformations need to *warp* the original image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsYe4_Cbxwl0"
      },
      "source": [
        "1. Cropping\n",
        "2. Rotation\n",
        "3. Translation\n",
        "4. Resizing\n",
        "5. Flipping\n",
        "6. Affine transform\n",
        "7. Perspective transform\n",
        "8. Padding\n",
        "9. Split color channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hRzHHXIxwl1"
      },
      "source": [
        "circles = plt.imread(\"data/circles.jpg\")\n",
        "plt.imshow(circles)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhv9IglXxwl2"
      },
      "source": [
        "# 1.Image Cropping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GYVm6r7xwl3"
      },
      "source": [
        "patch = (300, 200)\n",
        "center = (190, 220)\n",
        "cropped_image = cv2.getRectSubPix(circles, patch, center)\n",
        "plt.imshow(cropped_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWFiOQRdxwl4"
      },
      "source": [
        "### crop function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRuP35Dixwl4"
      },
      "source": [
        "def crop(img, center, width, height):\n",
        "    return cv2.getRectSubPix(img, (width, height), center)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Ix1U3Pxwl5"
      },
      "source": [
        "cropped = crop(circles, center=(190, 220), width=300, height=200)\n",
        "plt.imshow(cropped)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEFcQcGjxwl5"
      },
      "source": [
        "# **2. Rotation-cv2.warpAffine**\n",
        "- get the transform matrix with `cv2.getRotationMatrix2D`\n",
        "- params to `cv2.getRotationMatrix2D`: center, angle(+ -> counterclockwise), scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzgaHwbgxwl6"
      },
      "source": [
        "cat = cv2.imread(\"data/cat.jpg\")[:, :, ::-1]\n",
        "center = cat.shape[1]/2, cat.shape[0]/2\n",
        "angle = 30\n",
        "scale = 1.0\n",
        "\n",
        "M = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "rotated_cat = cv2.warpAffine(cat, M, (int(cat.shape[1]*1.3), int(cat.shape[0]*1.3)), borderValue=(255, 255, 255))\n",
        "plt.imshow(cat)\n",
        "plt.figure()\n",
        "plt.imshow(rotated_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaiKRFTSxwl6"
      },
      "source": [
        "### rotation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0paRLZbZxwl7"
      },
      "source": [
        "def rotate(image, angle, border_color=None):\n",
        "    # grab the dimensions of the image and then determine the\n",
        "    # center\n",
        "    if border_color == None:\n",
        "        border_color=(255, 255, 255)\n",
        "\n",
        "    (h, w) = image.shape[:2]\n",
        "    (cX, cY) = (w // 2, h // 2)\n",
        " \n",
        "    # grab the rotation matrix (applying the negative of the\n",
        "    # angle to rotate clockwise), then grab the sine and cosine\n",
        "    # (i.e., the rotation components of the matrix)\n",
        "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        " \n",
        "    # compute the new bounding dimensions of the image\n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        " \n",
        "    # adjust the rotation matrix to take into account translation\n",
        "    M[0, 2] += (nW / 2) - cX\n",
        "    M[1, 2] += (nH / 2) - cY\n",
        " \n",
        "    # perform the actual rotation and return the image\n",
        "    return cv2.warpAffine(image, M, (nW, nH), borderValue=border_color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdrniq9wxwl7"
      },
      "source": [
        "rotated_image1 = rotate(cat, angle=45, border_color = (200, 200, 200))\n",
        "rotated_image2 = rotate(cat, angle=60, border_color = (200, 200, 200))\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.subplot(131)\n",
        "plt.imshow(cat)\n",
        "plt.subplot(132)\n",
        "plt.imshow(rotated_image1)\n",
        "plt.subplot(133)\n",
        "plt.imshow(rotated_image2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkDmsQC8xwl7"
      },
      "source": [
        "# **3. Translation - cv.warpAffine**\n",
        "- params: img, transMatrix, dsize (dest image size)\n",
        "- transMatrix M should always be np.asarray([[1., 0., tx], [0., 1., ty]]), where tx and ty are offset on x and y (-x -> left, -y -> up). And it must be a float matrix\n",
        "- dsize should most of time be (src_img.shape[1], src_img.shape[0]), which are WIDTH and HEIGHT of images (in image domain instead of ndarray domain)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUL5oohzxwl8"
      },
      "source": [
        "cat = cv2.imread(\"data/cat.jpg\")[:, :, ::-1]\n",
        "shifted_cat = cv2.warpAffine(cat, \n",
        "               np.array([[1, 0, 30], \n",
        "                        [0, 1, 100]], \n",
        "                dtype = np.float),\n",
        "               dsize = (cat.shape[1], cat.shape[0])) # right down shift\n",
        "\n",
        "plt.imshow(cat)\n",
        "plt.figure()\n",
        "plt.imshow(shifted_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nfz4bVixwl8"
      },
      "source": [
        "### translation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8gc2LJJxwl9"
      },
      "source": [
        "def translate(img, x, y, border_size=None, border_color=None):\n",
        "    if border_size == None:\n",
        "        border_size = (img.shape[1], img.shape[0])\n",
        "    if border_color == None:\n",
        "        border_color=(255, 255, 255)\n",
        "   # return return cv2.warpAffine(img, np.array([[1, 0, x], [0, 1, y]]), border_size, borderValue=border_color)\n",
        "    return cv2.warpAffine(cat, \n",
        "               np.array([[1, 0, x], \n",
        "                        [0, 1, y]], \n",
        "                dtype = np.float),\n",
        "               border_size, borderValue=border_color) # right down shift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiuUAUpcxwl9"
      },
      "source": [
        "new = translate(cat, 50, 50, border_color=(255, 255, 0))\n",
        "plt.imshow(new)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2nuTqCVxwl-"
      },
      "source": [
        "# **4. Resizing - cv2.resize**\n",
        "- it is aspect-ratio (width/height) constant resize \n",
        "- params to cv2.resize: img, (with, height) of dest, interpolation_method, cv2.INTER_XX, e.g., cv2.INTER_AREA\n",
        "- you can also do it via rotation and warpAffine, but the effects are very different - in terms of the dimension of the resulted arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzqoyVHwxwl-"
      },
      "source": [
        "cat = cv2.imread(\"data/cat.jpg\")[:, :, ::-1]\n",
        "center = (100, 100)\n",
        "M = cv2.getRotationMatrix2D(center, 0, 0.3)\n",
        "resized_cat = cv2.warpAffine(cat, M, (cat.shape[1], cat.shape[0]))\n",
        "plt.imshow(cat)\n",
        "plt.figure()\n",
        "plt.imshow(resized_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5a-Z4Asxwl_"
      },
      "source": [
        "def bordered_resize(img, scale, center=None, border_size=None, border_color=None):\n",
        "    if center == None:\n",
        "        center = (int(img.shape[1]), int(img.shape[0]))\n",
        "    if border_size == None:\n",
        "        border_size = (img.shape[1], img.shape[0])\n",
        "    if border_color == None:\n",
        "        border_color=(255, 255, 255)\n",
        "    M = cv2.getRotationMatrix2D(center, 0, scale)\n",
        "    return cv2.warpAffine(img, M, border_size, borderValue=border_color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXGciG4axwl_"
      },
      "source": [
        "cat = cv2.imread(\"data/cat.jpg\")[:, :, ::-1]\n",
        "width, height = int(cat.shape[1]*0.3), int(cat.shape[0]*0.3)\n",
        "resized_cat = cv2.resize(cat, \n",
        "                          (width, height), \n",
        "                          interpolation = cv2.INTER_AREA,)\n",
        "plt.imshow(cat)\n",
        "plt.figure(figsize = (1.5, 1.5))\n",
        "plt.imshow(resized_cat)\n",
        "print(resized_cat.shape)\n",
        "\n",
        "cv2.imwrite(\"data/images/small_cat.jpg\", resized_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPZPZDuJxwmA"
      },
      "source": [
        "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
        "    # initialize the dimensions of the image to be resized and\n",
        "    # grab the image size\n",
        "    dim = None\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    # if both the width and height are None, then return the\n",
        "    # original image\n",
        "    if width is None and height is None:\n",
        "        return image\n",
        "\n",
        "    # check to see if the width is None\n",
        "    if width is None:\n",
        "        # calculate the ratio of the height and construct the\n",
        "        # dimensions\n",
        "        r = height / float(h)\n",
        "        dim = (int(w * r), height)\n",
        "\n",
        "    # otherwise, the height is None\n",
        "    else:\n",
        "        # calculate the ratio of the width and construct the\n",
        "        # dimensions\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "\n",
        "    # resize the image\n",
        "    resized = cv2.resize(image, dim, interpolation=inter)\n",
        "\n",
        "    # return the resized image\n",
        "    return resized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKeoYyOLxwmA"
      },
      "source": [
        "# **5. Flipping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL93Sd_VxwmB"
      },
      "source": [
        "cat = cv2.imread(\"data/cat.jpg\")[:, :, ::-1]\n",
        "fig, axes = plt.subplots(2, 2, figsize = (8, 8))\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "axes = axes.ravel()\n",
        "axes[0].imshow(cat)\n",
        "axes[1].imshow(cat[:, ::-1, :])\n",
        "axes[2].imshow(cat[::-1, :, :])\n",
        "axes[3].imshow(cat[::-1, ::-1, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBp4ZSEmxwmB"
      },
      "source": [
        "# 6. Affine transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBR-MB7bxwmB"
      },
      "source": [
        "#-*- coding:utf-8 -*-\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv2.imread('data/chessboard.jpg')\n",
        "rows, cols, ch = img.shape\n",
        "\n",
        "# pts1의 좌표에 표시. Affine 변환 후 이동 점 확인.\n",
        "cv2.circle(img, (200,100), 20, (255,0,0),-1)\n",
        "cv2.circle(img, (400,100), 20, (0,255,0),-1)\n",
        "cv2.circle(img, (200,200), 20, (0,0,255),-1)\n",
        "\n",
        "pts1 = np.float32([[200,100],[400,100],[200,200]])\n",
        "pts2 = np.float32([[200,300],[400,200],[200,400]])\n",
        "\n",
        "M = cv2.getAffineTransform(pts1, pts2)\n",
        "\n",
        "dst = cv2.warpAffine(img, M, (cols,rows))\n",
        "\n",
        "plt.subplot(121),plt.imshow(img),plt.title('image')\n",
        "plt.subplot(122),plt.imshow(dst),plt.title('Affine')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIAswPA7xwmC"
      },
      "source": [
        "# 7. Perspective Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcsnzYcuxwmC"
      },
      "source": [
        "#-*- coding:utf-8 -*-\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv2.imread('data/Railroad-Tracks-Perspective.jpg')\n",
        "# [x,y] 좌표점을 4x2의 행렬로 작성\n",
        "# 좌표점은 좌상->좌하->우상->우하\n",
        "\n",
        "# pts1의 좌표에 표시. perspective 변환 후 이동 점 확인.\n",
        "cv2.circle(img, (220,400), 10, (255,0,0),-1)\n",
        "cv2.circle(img, (410,400), 10, (0,255,0),-1)\n",
        "cv2.circle(img, (120,600), 10, (0,0,255),-1)\n",
        "cv2.circle(img, (500,600), 10, (0,0,0),-1)\n",
        "\n",
        "pts1 = np.float32([[220,400],[120,600],[410,400],[500,600]])\n",
        "\n",
        "# 좌표의 이동점\n",
        "pts2 = np.float32([[10,10],[10,1000],[1000,10],[1000,1000]])\n",
        "\n",
        "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "\n",
        "dst = cv2.warpPerspective(img, M, (1100,1100))\n",
        "\n",
        "plt.subplot(121),plt.imshow(img),plt.title('image')\n",
        "plt.subplot(122),plt.imshow(dst),plt.title('Perspective')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOV5nn1qxwmC"
      },
      "source": [
        "# 8. Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGYHEEmbxwmC"
      },
      "source": [
        "img = cv2.imread('data/beach.jpg')[:,:,::-1]\n",
        "bordersize = 100\n",
        "color = [255, 255, 255]\n",
        "bordered_img=cv2.copyMakeBorder(img, \n",
        "                                top=bordersize,bottom=bordersize, \n",
        "                                left=bordersize, right=bordersize, \n",
        "                                borderType= cv2.BORDER_CONSTANT, \n",
        "                                value=color )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypp1ScpJxwmC"
      },
      "source": [
        "#cv2.circle(bordered_img, (300, 320), radius = 10, color = [255, 0 ,0])\n",
        "plt.imshow(bordered_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0QD3zfhxwmD"
      },
      "source": [
        "## RGB images - BGR to RGB\n",
        "beach = cv2.imread(\"data/beach.jpg\")[:,:,::-1]\n",
        "plt.imshow(beach)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJug3rCmxwmD"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "BLUE = (0,0,255)\n",
        "\n",
        "img1 = beach ## no need to explicitly copy\n",
        "\n",
        "replicate = cv2.copyMakeBorder(img1,100,100,100,100,cv2.BORDER_REPLICATE)\n",
        "reflect = cv2.copyMakeBorder(img1,100,100,100,100,cv2.BORDER_REFLECT)\n",
        "reflect101 = cv2.copyMakeBorder(img1,100,100,100,100,cv2.BORDER_REFLECT_101)\n",
        "wrap = cv2.copyMakeBorder(img1,100,100,100,100,cv2.BORDER_WRAP)\n",
        "constant= cv2.copyMakeBorder(img1,100,100,100,100,cv2.BORDER_CONSTANT,value=BLUE)\n",
        "\n",
        "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
        "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
        "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
        "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
        "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
        "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE_RKo4wxwmE"
      },
      "source": [
        "# ***9. Split Color Channels***\n",
        "- using cv2.split and cv2.merge needs to stick with (BGR) channel encoding, which might be more troublesome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMulrU-kxwmE"
      },
      "source": [
        "wave = cv2.imread(\"data/circles.jpg\")[:,:,::-1]\n",
        "fig, axes = plt.subplots(2, 2, figsize = (8, 8))\n",
        "axes = axes.ravel()\n",
        "\n",
        "fig.tight_layout()\n",
        "axes[0].imshow(wave)\n",
        "axes[0].set_title(\"original\")\n",
        "axes[1].imshow(wave[:, :, 0], cmap = plt.cm.gray)\n",
        "axes[1].set_title(\"red\")\n",
        "axes[2].imshow(wave[:, :, 1], cmap = plt.cm.gray)\n",
        "axes[2].set_title(\"green\")\n",
        "axes[3].imshow(wave[:, :, 2], cmap = plt.cm.gray)\n",
        "axes[3].set_title(\"blue\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp9k1x6gxwmE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt-jmqOAxwmF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}