{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5H90HV799Qn"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "#import necessary libraries.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "layer = tf.keras.layers\n",
    "\n",
    "print('check tensorflow version : ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of train dataset : \", x_train.shape)\n",
    "print(\"The shape of test dataset : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sequential model\n",
    "\n",
    "Keras에서 Sequential modeling은 신경망 구조를 만드는 가장 간단한 방법이다. 신경망의 모든 계층이 직렬 구조를 갖을 때 사용할 수 있다.\n",
    "Sequential model은 높은 직관성과 가독성으로 복잡한 신경망의 하위 구조를 만들 때 활용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "'''\n",
    "또 다른 방식인 add 메서드를 통한 레이어 추가입니다.\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
    "# fit 메서드에 입력 X와 정답 Y 그리고 학습 횟수인 epochs을 결정할 수 있습니다. \n",
    "# validation_split은 학습데이터 중 일부를 자동으로 validation_set으로 배정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-XSanJS99Qz"
   },
   "source": [
    "# tip.keras model build\n",
    "\n",
    "keras에서 모델을 만들기 위해 알아야 할 3가지 자료형인 model, layer, tensor가 있습니다.\n",
    "\n",
    "- model은 layer를 엮은 네트워크 객체라고 할 수 있습니다.\n",
    "\n",
    "- 인공신경망을 구성하는 하위 계층을 의미합니다.\n",
    "\n",
    "- tensor는 layer와 layer 사이의 입력과 출력을 의미합니다. TensorFlow는 flow graph의 형태이기 때문에 tensor는 데이터가 중간에 저장되는 일종의 다차원 배열입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQzYPc8d99Q1"
   },
   "outputs": [],
   "source": [
    "#layer는 tf.keras.layers 아래의 클래스로 만들 수 있다.\n",
    "d1 = tf.keras.layers.Dense(8, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KAyO91o99Q5"
   },
   "outputs": [],
   "source": [
    "print(type(d1)) #레이어의 타입을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKxUmgGU99Q-"
   },
   "outputs": [],
   "source": [
    "# 각 layer 클래스는 method로 init, build, call를 갖는다. \n",
    "# init은 객체가 만들어지는 단계이고, tf.keras.layers.Dense(32, activation='relu')를 선언했을 때 실행된다.\n",
    "# build는 실제로 layer가 파라미터를 갖는 단계, call은 layer가 가진 parameter로 데이터를 계산하는 단계이다.\n",
    "\n",
    "print(d1.get_weights()) #weight는 build되지 않았기 때문에 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3i4f9Zqp99RG"
   },
   "outputs": [],
   "source": [
    "# build는 layer가 첫 번째로 call됐을 때 파라미터를 생성함. 특정 데이터를 입력하기 애매하기 때문에 보통 tf.keras.Input을 사용함.\n",
    "inputs = tf.keras.Input(shape=(4)) #shape를 정해주기 위한 placeholder 텐서\n",
    "print('type of inputs', type(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer의 input shape이 정해져야 layer가 build 단계에서 파라미터의 shape을 결정할 수 있음.\n",
    "d1_output = d1(inputs)\n",
    "print('weight shape : ', d1.get_weights()[0].shape,\n",
    "      '\\n-------------------------------------------------\\n',\n",
    "      'bias shape : ', d1.get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blVFGmVx99RK"
   },
   "outputs": [],
   "source": [
    "# build가 된 layer는 이제 입력으로 데이터를 받으면 output을 계산한다.\n",
    "d1_output = d1(np.ones([1,4], dtype=np.float32))\n",
    "print('d1_output의 타입', type(d1_output)) # 계산 결과의 자료형은 tensor\n",
    "print('\\n-------------------------------------------------\\n')\n",
    "print(d1_output.numpy()) #tf 2.0은 eager excution을 default로 제공하여 현재 tensor가 가지고 있는 값을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvOmC1iOaKXZ"
   },
   "source": [
    "# 2. Functional API\n",
    "\n",
    "Keras에서 Funtional API는 유연한 신경망을 구현할 수 있도록 한다. 신경망의 구현은 앞선 레이어의 출력텐서를 다음 레이어의 입력텐서로 선언해주는 방식으로 이루어진다. 이때 레이어 대신 모델(sequential model 포함)을 하위 구조로 사용이 가능해 계층화된 복잡한 신경망을 쉽게 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9mS_YIkaKXa"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28,1))  # Returns a placeholder tensor\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzfXcZ7jaKXa"
   },
   "outputs": [],
   "source": [
    "#make sure you have already graphviz, pydot, pydotplus libraries.\n",
    "tf.keras.utils.plot_model(model, 'my_first_model_with_shape_info.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wg2pVD5uaKXb"
   },
   "outputs": [],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-WDu9tbaKXc"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_HtgVt7aKXc"
   },
   "source": [
    "## model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04Kq7LCsaKXc"
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\") #it saves your model and parameters\n",
    "model.save_weights(\"weights.h5\") #it saves your parameters only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOECR_2oaKXc"
   },
   "outputs": [],
   "source": [
    "new_model = tf.kera.models.load_model(\"model.h5\")\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZRVrx60aKXd"
   },
   "outputs": [],
   "source": [
    "del model\n",
    "del new_model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uB6pGjrRaKXd"
   },
   "source": [
    "### more complex modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMRBYlDRaKXd"
   },
   "outputs": [],
   "source": [
    "#시나리오 : 영상과 텍스트(integer encoded)를 입력으로 받는 multi-modal 모델을 구현한다.\n",
    "#테스크는 분류이다.\n",
    "\n",
    "input_layer1 = tf.keras.Input(shape=(28,28,3)) #입력영상\n",
    "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(input_layer1)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(x)\n",
    "y1 = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "input_layer2 = tf.keras.Input(shape=(50)) #time step 50의 텍스트 문장(정수 인코딩)\n",
    "vocab = 2000 #단어수\n",
    "x = tf.keras.layers.Embedding(vocab, 64)(input_layer2) #word embedding dimension = 64\n",
    "x = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(x)\n",
    "y2 = tf.keras.layers.LSTM(64, activation='tanh')(x)\n",
    "\n",
    "#정보통합\n",
    "y = tf.concat([y1,y2], axis=-1)\n",
    "\n",
    "#분류기\n",
    "hidden = tf.keras.layers.Dense(64, activation='relu')(y)\n",
    "class_num = 5\n",
    "pred = tf.keras.layers.Dense(class_num, activation='softmax')(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEWFTKi7aKXd"
   },
   "outputs": [],
   "source": [
    "complex_model = tf.keras.Model([input_layer1, input_layer2], pred)\n",
    "tf.keras.utils.plot_model(complex_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en3Ow2yCaKXe"
   },
   "source": [
    "# Another way?\n",
    "\n",
    "더 유연한 모델의 기능을 구현하고 싶은 경우 Subclassing 방식으로 모델의 동작 방식을 정의해줄 수 있다.\n",
    "tf.keras의 Model 클래스를 상속하여, 개발자가 추가적인 함수를 구현한다.\n",
    "그러나 복잡성이 늘어나는 만큼 기존 API와의 호환성을 유의하여 사용해야 한다.\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/custom_layers_and_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEGIp1vMaKXe"
   },
   "source": [
    "# 3. Loop training\n",
    "\n",
    "model.fit 메서드는 편리한 인터페이스를 제공하지만 학습 알고리즘의 커스터마이징이 어렵다. 커스터마이징에는 새로운 Loss 함수 정의, 네트워크의 학습범위를 제어하는 것을 포함한다. Loop training 방식은 이름에서도 알 수 있듯이 Loop 구조 내에서 tf.GradientTape을 사용해 학습을 제어하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmktV8q5aKXe"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vui3_zfaKXe"
   },
   "outputs": [],
   "source": [
    "def custom_loss_example(target_y, predicted_y):\n",
    "  return tf.reduce_mean(tf.square(target_y - predicted_y))\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEzZG5WwaKXf"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ill1SARf99Rd"
   },
   "source": [
    "# Split pre-trained model for customized transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5KfdwAS99Re"
   },
   "outputs": [],
   "source": [
    "# You can take famous image processing architecture, resnet101.\n",
    "\n",
    "\n",
    "#https://keras.io/applications/#usage-examples-for-image-classification-models\n",
    "inputs = tf.keras.Input(shape=(240, 240, 3))\n",
    "resnet101 = tf.keras.applications.ResNet101(include_top=False, weights='imagenet', input_tensor=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzdMSnqC99Rl"
   },
   "outputs": [],
   "source": [
    "#plot the architecture of resnet 101\n",
    "tf.keras.utils.plot_model(resnet101, 'resnet101.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcXDexqf99Rp"
   },
   "outputs": [],
   "source": [
    "model_input = resnet101.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFCPgNlJ99Rt"
   },
   "outputs": [],
   "source": [
    "model_output = resnet101.get_layer('conv2_block1_add').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJ-warkc99R1"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.Model(inputs=model_input, outputs=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOeT6Az599R6"
   },
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Keras_funtional_API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
