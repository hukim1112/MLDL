{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Y5H90HV799Qn",
    "outputId": "350119f1-e4cc-4a6d-ee32-020712b562db"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "#import necessary libraries.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "layer = tf.keras.layers\n",
    "\n",
    "print('check tensorflow version : ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-XSanJS99Qz"
   },
   "source": [
    "# keras model build\n",
    "\n",
    "keras에서 모델을 만들기 위해 알아야 할 3가지 자료형인 layer, tensor, model이 있다.\n",
    "layer는 인공신경망을 구성하는 하위 계층을 의미하고, tensor는 layer와 layer 사이의 입력과 출력을 말한다. TensorFlow는 flow graph의 형태이기 때문에 tensor는 데이터에 따라 계속 변하는 변동 변수이기 때문에 특정 값을 가진다고 할 수 없음. 그러나 tf 2.0부터 tensor의 값을 tensor.numpy()의 형태로 쉽게 확인할 수 있음. 마지막으로 model은 layer를 엮은 네트워크 객체라고 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQzYPc8d99Q1"
   },
   "outputs": [],
   "source": [
    "#layer는 tf.keras.layers 아래의 클래스로 만들 수 있다.\n",
    "d1 = tf.keras.layers.Dense(32, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3KAyO91o99Q5",
    "outputId": "a9b3c881-b59e-4ef3-f11c-c9b55360e984"
   },
   "outputs": [],
   "source": [
    "print(type(d1)) #레이어의 타입을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WKxUmgGU99Q-",
    "outputId": "1c9d2b20-8fc3-463e-f4d1-9e43aa215c0d"
   },
   "outputs": [],
   "source": [
    "# 각 layer 클래스는 method로 init, build, call를 갖는다. \n",
    "# init은 객체가 만들어지는 단계이고, tf.keras.layers.Dense(32, activation='relu')를 선언했을 때 실행된다.\n",
    "# build는 실제로 layer가 파라미터를 갖는 단계, call은 layer가 가진 parameter로 데이터를 계산하는 단계이다.\n",
    "\n",
    "print(d1.get_weights()) #weight는 build되지 않았기 때문에 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "3i4f9Zqp99RG",
    "outputId": "3c96448d-23dc-43bb-8b91-972a2eb35d19"
   },
   "outputs": [],
   "source": [
    "# build는 layer가 첫 번째로 call됐을 때 파라미터를 생성함. 특정 데이터를 입력하기 애매하기 때문에 보통 tf.keras.Input을 사용함.\n",
    "inputs = tf.keras.Input(shape=(784)) #shape를 정해줌. \n",
    "#layer의 input shape이 정해져야 layer가 build 단계에서 파라미터의 shape을 결정할 수 있음.\n",
    "print('type of inputs', type(inputs))\n",
    "d1_output = d1(inputs)\n",
    "print('weights of d1', d1.get_weights(), \n",
    "      '\\n-------------------------------------------------\\n',\n",
    "      'weight shape : ', d1.get_weights()[0].shape,\n",
    "      '\\n-------------------------------------------------\\n',\n",
    "      'bias shape : ', d1.get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "blVFGmVx99RK",
    "outputId": "21ab174b-2df7-4986-8752-24a5cf9b7e80"
   },
   "outputs": [],
   "source": [
    "# build가 된 layer는 이제 입력으로 데이터를 받으면 output을 계산한다.\n",
    "d1_output = d1(np.ones([1,784], dtype=np.float32))\n",
    "print('d1_output의 타입', type(d1_output)) # 계산 결과의 자료형은 tensor\n",
    "print('\\n-------------------------------------------------\\n')\n",
    "print(d1_output.numpy()) #tf 2.0은 eager excution을 default로 제공하여 현재 tensor가 가지고 있는 값을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "FTS5jydD99RV",
    "outputId": "39286c57-af4b-42c3-bead-8bb3ae9968ce"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of train dataset : \", x_train.shape)\n",
    "print(\"The shape of test dataset : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "print(\"The shape of train dataset : \", x_train.shape)\n",
    "print(\"The shape of test dataset : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLT518BV99RZ"
   },
   "source": [
    "# 1. Sequential model\n",
    "\n",
    "Keras에서 Sequential modeling은 신경망 구조를 만드는 가장 간단한 방법이다. 신경망의 모든 계층이 직렬 구조를 갖을 때 사용할 수 있다.\n",
    "Sequential model은 높은 직관성과 가독성으로 복잡한 신경망의 하위 구조를 만들 때 활용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "'''\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "import math\n",
    "steps_per_epoch=math.ceil(60000/32)\n",
    "model.fit(train_ds, epochs=5, steps_per_epoch=steps_per_epoch)\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functional API\n",
    "\n",
    "Keras에서 Funtional API는 유연한 신경망을 구현할 수 있도록 한다. 신경망의 구현은 앞선 레이어의 출력텐서를 다음 레이어의 입력텐서로 선언해주는 방식으로 이루어진다. 이때 레이어 대신 모델(sequential model 포함)을 하위 구조로 사용이 가능해 계층화된 복잡한 신경망을 쉽게 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28,1))  # Returns a placeholder tensor\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure you have already graphviz, pydot, pydotplus libraries.\n",
    "tf.keras.utils.plot_model(model, 'my_first_model_with_shape_info.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_ds))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "import math\n",
    "steps_per_epoch=math.ceil(60000/32)\n",
    "model.fit(train_ds, epochs=5, steps_per_epoch=steps_per_epoch)\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\") #it saves your model and parameters\n",
    "model.save_weights(\"weights.h5\") #it saves your parameters only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.kera.models.load_model(\"model.h5\")\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del new_model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more complex modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시나리오 : 영상과 텍스트(integer encoded)를 입력으로 받는 multi-modal 모델을 구현한다.\n",
    "#테스크는 분류이다.\n",
    "\n",
    "input_layer1 = tf.keras.Input(shape=(28,28,3)) #입력영상\n",
    "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(input_layer1)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(x)\n",
    "y1 = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "input_layer2 = tf.keras.Input(shape=(50)) #time step 50의 텍스트 문장(정수 인코딩)\n",
    "vocab = 2000 #단어수\n",
    "x = tf.keras.layers.Embedding(vocab, 64)(input_layer2) #word embedding dimension = 64\n",
    "x = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(x)\n",
    "y2 = tf.keras.layers.LSTM(64, activation='tanh')(x)\n",
    "\n",
    "#정보통합\n",
    "y = tf.concat([y1,y2], axis=-1)\n",
    "\n",
    "#분류기\n",
    "hidden = tf.keras.layers.Dense(64, activation='relu')(y)\n",
    "class_num = 5\n",
    "pred = tf.keras.layers.Dense(class_num, activation='softmax')(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model = tf.keras.Model([input_layer1, input_layer2], pred)\n",
    "tf.keras.utils.plot_model(complex_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another way?\n",
    "\n",
    "더 유연한 모델의 기능을 구현하고 싶은 경우 Subclassing 방식으로 모델의 동작 방식을 정의해줄 수 있다.\n",
    "tf.keras의 Model 클래스를 상속하여, 개발자가 추가적인 함수를 구현한다.\n",
    "그러나 복잡성이 늘어나는 만큼 기존 API와의 호환성을 유의하여 사용해야 한다.\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/custom_layers_and_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loop training\n",
    "\n",
    "model.fit 메서드는 편리한 인터페이스를 제공하지만 학습 알고리즘의 커스터마이징이 어렵다. 커스터마이징에는 새로운 Loss 함수 정의, 네트워크의 학습범위를 제어하는 것을 포함한다. Loop training 방식은 이름에서도 알 수 있듯이 Loop 구조 내에서 tf.GradientTape을 사용해 학습을 제어하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_example(target_y, predicted_y):\n",
    "  return tf.reduce_mean(tf.square(target_y - predicted_y))\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ill1SARf99Rd"
   },
   "source": [
    "# Split pre-trained model for customized transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Z5KfdwAS99Re",
    "outputId": "e37117a8-b7e2-4312-a0c9-8c64ae36f7c2"
   },
   "outputs": [],
   "source": [
    "# You can take famous image processing architecture, resnet101.\n",
    "\n",
    "\n",
    "#https://keras.io/applications/#usage-examples-for-image-classification-models\n",
    "inputs = tf.keras.Input(shape=(240, 240, 3))\n",
    "resnet101 = tf.keras.applications.ResNet101(include_top=False, weights='imagenet', input_tensor=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "h0792iNG99Ri",
    "outputId": "1db5a01a-a34a-4de3-f42a-c58ee271a668"
   },
   "outputs": [],
   "source": [
    "for l in resnet101.layers[:10]:\n",
    "  print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nzdMSnqC99Rl",
    "outputId": "fb0ba806-48ca-4203-c670-08daa01b195d"
   },
   "outputs": [],
   "source": [
    "#plot the architecture of resnet 101\n",
    "tf.keras.utils.plot_model(resnet101, 'resnet101.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcXDexqf99Rp"
   },
   "outputs": [],
   "source": [
    "model_input = resnet101.get_layer('input_5').input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFCPgNlJ99Rt"
   },
   "outputs": [],
   "source": [
    "model_output = resnet101.get_layer('conv4_block23_out').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJ-warkc99R1"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.Model(inputs=model_input, outputs=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOeT6Az599R6",
    "outputId": "94229e17-aae0-4fb3-9475-77fd3d129021"
   },
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Keras_funtional_API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
