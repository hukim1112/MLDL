{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT_indoor_dataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0MzLoLGg67j3auQukrrKE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hukim1112/MLDL/blob/master/lecture8/MIT_indoor_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MIT indoor classification 데이터셋"
      ],
      "metadata": {
        "id": "XSxqIarV4v26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 분류할 데이터셋 다운로드\n",
        "\n",
        "colab 종류 시, 파일을 다시 다운로드해야하므로, 자신의 google drive에 사본을 저장하는 방법도 좋습니다. \n",
        "\n",
        "참고 : https://ikaros79.tistory.com/entry/03-Google-Colaboraty-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0\n",
        "\n",
        "\n",
        "gdown의 rate-limit로 인해 24시간 내 많은 횟수로 다운로드를 시도할 경우 permission denied가 발생하는 문제가 있습니다. 그 경우 아래 링크의 구글 드라이브에 직접 접근해 학습데이터를 다운하신 뒤 코랩에 업로드해서 사용하시기 바랍니다.\n",
        "\n",
        "https://drive.google.com/file/d/1kUY5d23MTPbf5P1bi4eSss7_yntYJrWt/view\n"
      ],
      "metadata": {
        "id": "wBxkvFV-zHQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1kUY5d23MTPbf5P1bi4eSss7_yntYJrWt #download"
      ],
      "metadata": {
        "id": "Fq1cDOhMW0l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/train_imgs.zip\" #unzip"
      ],
      "metadata": {
        "id": "lZIgIty0z3x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 import"
      ],
      "metadata": {
        "id": "srr7a2oy8z0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "LJk1gPA9zLcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파일경로로 사진에 접근하기"
      ],
      "metadata": {
        "id": "f3ArSA-t0D5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "data_dir = \"/content/train_imgs\"\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count) #총 학습데이터 수"
      ],
      "metadata": {
        "id": "3X_SGDJqxusg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "roses = list(data_dir.glob('bakery/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ],
      "metadata": {
        "id": "svUdVjFqy2OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***필독! 영상 중 decoding 오류 영상을 제거합니다***\n",
        "\n",
        "전체 데이터 중 소수의 bmp로 인코딩된 영상 파일 존재\n",
        "\n",
        "\n",
        "- 예외처리로 tf.image.decode_bmp로 디코딩\n",
        "- 파일 제거 (권장)"
      ],
      "metadata": {
        "id": "5UVXl6hK8MuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5개 파일을 제거합니다.\n",
        "!rm \"/content/train_imgs/laundromat/Laundry_Room_bmp.jpg\"\n",
        "!rm '/content/train_imgs/auditorium/auditorium986_120.jpg'\n",
        "!rm '/content/train_imgs/kindergarden/classroom_north_bmp.jpg'\n",
        "!rm '/content/train_imgs/auditorium/auditorium776_118.jpg'\n",
        "!rm '/content/train_imgs/waitingroom/Bistro_3_BMP.jpg'"
      ],
      "metadata": {
        "id": "mmIB4UPG8M10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파일 경로로 텐서플로우 데이터셋 오브젝트 생성"
      ],
      "metadata": {
        "id": "VRKC4CkW1MC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "보다 세밀한 제어를 위해 `tf.data`을 사용하여 자체 입력 파이프라인을 작성할수 있습니다. 이 섹션에서는 이전에 다운로드한 zip 파일 경로부터 시작하여 이를 수행하는 방법을 보여줍니다."
      ],
      "metadata": {
        "id": "s73FFEoH2p_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
        "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
        "\n",
        "#data_dir의 하위 폴더 및 파일은 다음과 같습니다.\n",
        "print(os.listdir(data_dir))\n",
        "#파일의 트리 구조를 사용하여 `class_names` 목록을 리스트로 만들 수 있습니다.\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "LQGs6AnT1Ma4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터세트를 훈련 및 검증으로 분할합니다."
      ],
      "metadata": {
        "id": "4rm0N8KO2ubt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = int(image_count * 0.2)\n",
        "\n",
        "val_ds = list_ds.take(val_size) #val size만큼 취하고,\n",
        "train_ds = list_ds.skip(val_size) #나머지를 train dataset으로.."
      ],
      "metadata": {
        "id": "rrcBNx092doh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(val_ds).numpy())"
      ],
      "metadata": {
        "id": "HP7NPmYe2wkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파일 경로를 `(img, label)` 쌍으로 변환하는 간단한 함수를 작성합니다."
      ],
      "metadata": {
        "id": "pTTTzS5L3ARl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)\n",
        "\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "metadata": {
        "id": "dnP0BHdL3GSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "metadata": {
        "id": "4_5wwOXT3iWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(img, label):\n",
        "    img = tf.image.resize_with_crop_or_pad(img, img_height + 8, img_width + 8) \n",
        "    # Random crop back to the original size\n",
        "    img = tf.image.random_crop(img, size=[img_height, img_width, 3])\n",
        "    img = tf.image.random_brightness(img, 0.15)\n",
        "    img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "    img = tf.image.random_hue(img, 0.5)\n",
        "    img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "    return img, label"
      ],
      "metadata": {
        "id": "9WyE800i3k9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)"
      ],
      "metadata": {
        "id": "Z1pphHHR3pDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in train_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "metadata": {
        "id": "u7GmYYMQ3q7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성능을 위한 데이터세트 구성하기"
      ],
      "metadata": {
        "id": "iiky7-P_4Y6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 데이터세트로 모델을 훈련하려면 데이터에 대해 다음이 필요합니다.\n",
        "\n",
        "- 잘 섞는다.\n",
        "- 배치 처리한다.\n",
        "- 가능한 빨리 배치를 사용할 수 있어야 한다.\n",
        "\n",
        "이러한 기능은 `tf.data` API를 사용하여 추가할 수 있습니다. 자세한 내용은 [입력 파이프라인 성능](../../guide/performance/datasets) 가이드를 참조하세요."
      ],
      "metadata": {
        "id": "5Sdd8Fa24bek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ],
      "metadata": {
        "id": "C56MHOi74ZQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 시각화하기\n",
        "\n",
        "이 데이터세트를 이전에 작성한 데이터세트와 유사하게 시각화할 수 있습니다."
      ],
      "metadata": {
        "id": "QYM9fv0A4fYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "zO0TQYNe4fuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 데이터셋 루프의 shape 확인"
      ],
      "metadata": {
        "id": "btqItWFK8RAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for imgs, labels in train_ds:\n",
        "  print(imgs.shape)"
      ],
      "metadata": {
        "id": "v8VNhZh74iDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}