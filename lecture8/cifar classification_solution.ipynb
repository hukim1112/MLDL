{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztWu3NJIrz1C"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJEsy0HGrz1E"
      },
      "source": [
        "print(tf.__version__) #version check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bht2QF5crz1E"
      },
      "source": [
        "# 1. Load cifar10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADr5RdBZrz1E"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data() # data load\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 # data preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxvN4j5tstpi"
      },
      "source": [
        "print(x_train.shape, y_train.shape) #check your data shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8xs6X9zqYXo"
      },
      "source": [
        "# Cifar 데이터 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnFEUEycqVif"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "fig, axes = plt.subplots(3,3)\n",
        "for idx in range(9):\n",
        "  axes[idx//3, idx%3].imshow(x_train[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj2yRORLrz1F"
      },
      "source": [
        "# 2. Build your Convolutional Neural Network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEHLL0FPrz1F"
      },
      "source": [
        "def build_CNN():\n",
        "  CNN = tf.keras.models.Sequential()\n",
        "  CNN.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "  CNN.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "  CNN.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.Flatten())\n",
        "  CNN.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "  CNN.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  return CNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0E-WIPjtkca"
      },
      "source": [
        "your_cnn = build_CNN()\n",
        "your_cnn.build([None, 32, 32, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RFHmPO6rz1G"
      },
      "source": [
        "your_cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssOt5ROWrz1H"
      },
      "source": [
        "history = your_cnn.fit(x_train, y_train, epochs=20, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkQqSwGdzDpI"
      },
      "source": [
        "your_cnn.evaluate(x_test,  y_test, verbose=2) # 테스트"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_PhPmTwtwnb"
      },
      "source": [
        "fig = plt.subplot(1,2,1)\n",
        "plt.plot(history.epoch, history.history['loss'], '-', label='loss')\n",
        "plt.plot(history.epoch, history.history['val_loss'], '--', label='val_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "fig = plt.subplot(1,2,2)\n",
        "plt.plot(history.epoch, history.history['accuracy'], '-', label='accuracy')\n",
        "plt.plot(history.epoch, history.history['val_accuracy'], '--', label='val_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VdNEmJcx-Fu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxDqdZz-s4qQ"
      },
      "source": [
        "# 3.Train your model smarter\n",
        "\n",
        "모델 학습 시 조금 더 똑똑하게 학습하기 위한 유용한 도구들이 존재합니다.\n",
        "그 중 하나는 Keras에서는 [Callback함수를 활용](https://https://www.tensorflow.org/guide/keras/train_and_evaluate#%EC%BD%9C%EB%B0%B1_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)하는 것입니다.\n",
        "\n",
        "- EarlyStopping : validation loss가 일정 이상 줄어들지 않으면, 학습을 정지합니다.\n",
        "- ModelCheckpoint : 학습 중 모델을 일정 주기로 모델을 저장합니다.\n",
        "- TensorBoard : [TensorBoard](https://www.tensorflow.org/tensorboard)에서 읽을 수 있는 형태로 log를 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvGMHXahs3YX"
      },
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "            # Stop training when `val_loss` is no longer improving\n",
        "            monitor=\"val_loss\",\n",
        "            # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
        "            min_delta=1e-2,\n",
        "            # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "        ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        # Path where to save the model\n",
        "        # The two parameters below mean that we will overwrite\n",
        "        # the current checkpoint if and only if\n",
        "        # the `val_loss` score has improved.\n",
        "        # The saved model name will include the current epoch.\n",
        "        filepath=\"step3_{epoch}.h5\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUbmi_9hxFPf"
      },
      "source": [
        "### Add Dropout layers\n",
        "\n",
        "모델의 성능을 개선하기 위해 스케일을 높일 경우 쉽게 과대적합될 수 있습니다.\n",
        "이것을 피하기 위해 몇 가지 Regularization 기법을 쓸 수 있습니다.\n",
        "이번에는 Dropout layer를 추가할 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjL9w_CUs3ai"
      },
      "source": [
        "def add_dropout():\n",
        "  CNN = tf.keras.models.Sequential()\n",
        "  CNN.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "  CNN.add(tf.keras.layers.Dropout(0.25))\n",
        "  CNN.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "  CNN.add(tf.keras.layers.Dropout(0.25))\n",
        "  CNN.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  CNN.add(tf.keras.layers.Dropout(0.25))\n",
        "  CNN.add(tf.keras.layers.Flatten())\n",
        "  CNN.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "  CNN.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "  return CNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA3ehz7-xhu2"
      },
      "source": [
        "CNN_with_dropout = add_dropout()\n",
        "CNN_with_dropout.build([None, 32, 32, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuVClcFns3dD"
      },
      "source": [
        "CNN_with_dropout.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = CNN_with_dropout.fit(x_train, y_train, epochs=20, validation_split=0.2,\n",
        "                               callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyBJ8rrOz0Ln"
      },
      "source": [
        "fig = plt.subplot(1,2,1)\n",
        "plt.plot(history.epoch, history.history['loss'], '-', label='loss')\n",
        "plt.plot(history.epoch, history.history['val_loss'], '--', label='val_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "fig = plt.subplot(1,2,2)\n",
        "plt.plot(history.epoch, history.history['accuracy'], '-', label='accuracy')\n",
        "plt.plot(history.epoch, history.history['val_accuracy'], '--', label='val_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbMnKoW2xlIR"
      },
      "source": [
        "path_to_best_model = \"path/to/best/model\"\n",
        "best_model = tf.keras.models.load_model(path_to_best_model)\n",
        "best_model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTvKCcn-xvbd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGVF2vhYyCoo"
      },
      "source": [
        "# 4. 데이터 파이프라인과 데이터증폭\n",
        "\n",
        "텐서플로우 데이터 파이프라인은 학습데이터를 design하기 위한 멋진 인터페이스를 제공합니다. 주로 다음과 같은 절차를 밟습니다.\n",
        "\n",
        "- step 1. 텐서플로우 데이터셋 객체를 만든다.\n",
        "- step 2. map 함수로 데이터를 전처리한다.\n",
        "- step 3. 데이터파이프라인을 최적화한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5aXtGNUyCJ9"
      },
      "source": [
        "# step 1. 텐서플로우 데이터셋 객체를 만듭니다.\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)) \n",
        "num_train = len(train_ds)\n",
        "print(\"학습데이터 수 : \", num_train)\n",
        "\n",
        "# 학습셋, 검증셋 스플릿\n",
        "val_ds = train_ds.take(int(num_train*0.2))\n",
        "train_ds = train_ds.skip(int(num_train*0.2))\n",
        "\n",
        "# 테스트셋\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NFFbZTj3wAU"
      },
      "source": [
        "print(len(train_ds), len(val_ds), len(test_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0IAFCAZ1DLR"
      },
      "source": [
        "# step 2. 데이터를 전처리합니다.\n",
        "\n",
        "def augment(img,label):\n",
        "    img = tf.image.resize_with_crop_or_pad(img, 32 + 4, 32 + 4) \n",
        "    # Random crop back to the original size\n",
        "    img = tf.image.random_crop(img, size=[32, 32, 3])\n",
        "    img = tf.image.random_brightness(img, 0.15)\n",
        "    img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "    img = tf.image.random_hue(img, 0.2)\n",
        "    img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "    return img, label\n",
        "\n",
        "train_ds = train_ds.map(augment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjN5SlUoyCMe"
      },
      "source": [
        "# step 3. 파이프라인을 최적화해줍니다.\n",
        "\n",
        "train_ds = train_ds.shuffle(1000).batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_ds = val_ds.batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_ds = test_ds.batch(64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poojIsSAyCPB"
      },
      "source": [
        "CNN_with_dropout = add_dropout()\n",
        "CNN_with_dropout.build([None, 32, 32, 3])\n",
        "CNN_with_dropout.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "            # Stop training when `val_loss` is no longer improving\n",
        "            monitor=\"val_loss\",\n",
        "            # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
        "            min_delta=1e-2,\n",
        "            # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "        ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        # Path where to save the model\n",
        "        # The two parameters below mean that we will overwrite\n",
        "        # the current checkpoint if and only if\n",
        "        # the `val_loss` score has improved.\n",
        "        # The saved model name will include the current epoch.\n",
        "        filepath=\"step4_{epoch}.h5\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=1,\n",
        "    )\n",
        "]\n",
        "history = CNN_with_dropout.fit(train_ds, epochs=40, validation_data=val_ds,\n",
        "                               callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5HPkyaIyCRm"
      },
      "source": [
        "fig = plt.subplot(1,2,1)\n",
        "plt.plot(history.epoch, history.history['loss'], '-', label='loss')\n",
        "plt.plot(history.epoch, history.history['val_loss'], '--', label='val_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "fig = plt.subplot(1,2,2)\n",
        "plt.plot(history.epoch, history.history['accuracy'], '-', label='accuracy')\n",
        "plt.plot(history.epoch, history.history['val_accuracy'], '--', label='val_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TlZ99q5yCUL"
      },
      "source": [
        "path_to_best_model = \"path/to/best/model\"\n",
        "best_model = tf.keras.models.load_model(path_to_best_model)\n",
        "best_model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk23vHd6yCWs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H_X5nKt7u4c"
      },
      "source": [
        "# 5. Learning rate scheduler\n",
        "\n",
        "학습률(learning rate)은 가장 중요한 hyper-parameter 중 하나입니다. 일반적으로 학습초기부터 끝까지 동일한 학습률을 쓰는 것보다 약간씩 감소시키는 것이 더 좋을 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQN-56G17twa"
      },
      "source": [
        "CNN_with_dropout = add_dropout()\n",
        "CNN_with_dropout.build([None, 32, 32, 3])\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.95)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "CNN_with_dropout.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "            # Stop training when `val_loss` is no longer improving\n",
        "            monitor=\"val_loss\",\n",
        "            # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
        "            min_delta=1e-2,\n",
        "            # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "        ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        # Path where to save the model\n",
        "        # The two parameters below mean that we will overwrite\n",
        "        # the current checkpoint if and only if\n",
        "        # the `val_loss` score has improved.\n",
        "        # The saved model name will include the current epoch.\n",
        "        filepath=\"step5_{epoch}.h5\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=1,\n",
        "    )\n",
        "]\n",
        "history = CNN_with_dropout.fit(train_ds, epochs=40, validation_data=val_ds,\n",
        "                               callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkUGQSvt_w5s"
      },
      "source": [
        "fig = plt.subplot(1,2,1)\n",
        "plt.plot(history.epoch, history.history['loss'], '-', label='loss')\n",
        "plt.plot(history.epoch, history.history['val_loss'], '--', label='val_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "fig = plt.subplot(1,2,2)\n",
        "plt.plot(history.epoch, history.history['accuracy'], '-', label='accuracy')\n",
        "plt.plot(history.epoch, history.history['val_accuracy'], '--', label='val_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDNyIfJj_w9K"
      },
      "source": [
        "path_to_best_model = \"path/to/best/model\"\n",
        "best_model = tf.keras.models.load_model(path_to_best_model)\n",
        "best_model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB7Qg7t09xbk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPrQopRn9xqE"
      },
      "source": [
        "# 6. Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtdiwKFM_UDL"
      },
      "source": [
        "backbone = tf.keras.applications.EfficientNetB0(include_top=False,\n",
        "                                                   input_shape=(64,64,3),\n",
        "                                                   weights=\"imagenet\")\n",
        "# len(resnet_backbone.layers)\n",
        "# for layer in resnet_backbone.layers[:160]:\n",
        "#   layer.trainable = False\n",
        "\n",
        "classifier = tf.keras.Sequential([backbone,\n",
        "                                  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                  tf.keras.layers.Dense(128),\n",
        "                                  tf.keras.layers.BatchNormalization(),\n",
        "                                  tf.keras.layers.ReLU(),\n",
        "                                  tf.keras.layers.Dropout(0.2),\n",
        "                                  tf.keras.layers.Dense(64),\n",
        "                                  tf.keras.layers.BatchNormalization(),\n",
        "                                  tf.keras.layers.ReLU(),\n",
        "                                  tf.keras.layers.Dense(10, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S3Sm6EQA4Sz"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaNjfmmz7tzM"
      },
      "source": [
        "# step 1. 텐서플로우 데이터셋 객체를 만듭니다.\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data() # data load\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)) \n",
        "num_train = len(train_ds)\n",
        "print(\"학습데이터 수 : \", num_train)\n",
        "\n",
        "# 학습셋, 검증셋 스플릿\n",
        "val_ds = train_ds.take(int(num_train*0.2))\n",
        "train_ds = train_ds.skip(int(num_train*0.2))\n",
        "\n",
        "# 테스트셋\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtRfP-h_-C1y"
      },
      "source": [
        "# step 2. 데이터를 전처리합니다.\n",
        "\n",
        "def augment(img,label):\n",
        "    img = tf.image.resize_with_crop_or_pad(img, 32 + 4, 32 + 4) \n",
        "    # Random crop back to the original size\n",
        "    img = tf.image.random_crop(img, size=[32, 32, 3])\n",
        "    img = tf.image.random_brightness(img, 0.15)\n",
        "    img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "    img = tf.image.random_hue(img, 0.2)\n",
        "    img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "    return img, label\n",
        "\n",
        "def resize_image(img, label):\n",
        "  img = tf.image.resize(img, [64,64], method='bicubic')\n",
        "  img = tf.keras.applications.efficientnet.preprocess_input(img)\n",
        "  return img, label\n",
        "\n",
        "train_ds = train_ds.map(augment,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.map(resize_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(resize_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(resize_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpEmCU10-E60"
      },
      "source": [
        "# step 3. 파이프라인을 최적화해줍니다.\n",
        "\n",
        "train_ds = train_ds.shuffle(1000).batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_ds = val_ds.batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_ds = test_ds.batch(64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMloUdMB1g-O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anabD_16A20G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3398440-477b-4edf-86de-66a410f3d0b7"
      },
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=200,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "classifier.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "            # Stop training when `val_loss` is no longer improving\n",
        "            monitor=\"val_loss\",\n",
        "            # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
        "            min_delta=0.0,\n",
        "            # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "        ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        # Path where to save the model\n",
        "        # The two parameters below mean that we will overwrite\n",
        "        # the current checkpoint if and only if\n",
        "        # the `val_loss` score has improved.\n",
        "        # The saved model name will include the current epoch.\n",
        "        filepath=\"step6_{epoch}.h5\",\n",
        "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=1,\n",
        "    )\n",
        "]\n",
        "history = classifier.fit(train_ds, epochs=40, validation_data=val_ds,\n",
        "                               callbacks=callbacks)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.8188 - accuracy: 0.7284\n",
            "Epoch 00001: val_loss improved from inf to 0.41169, saving model to step6_1.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 134s 193ms/step - loss: 0.8188 - accuracy: 0.7284 - val_loss: 0.4117 - val_accuracy: 0.8611\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8485\n",
            "Epoch 00002: val_loss improved from 0.41169 to 0.31369, saving model to step6_2.h5\n",
            "625/625 [==============================] - 120s 191ms/step - loss: 0.4544 - accuracy: 0.8485 - val_loss: 0.3137 - val_accuracy: 0.8957\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8841\n",
            "Epoch 00003: val_loss improved from 0.31369 to 0.27141, saving model to step6_3.h5\n",
            "625/625 [==============================] - 121s 193ms/step - loss: 0.3434 - accuracy: 0.8841 - val_loss: 0.2714 - val_accuracy: 0.9103\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.9113\n",
            "Epoch 00004: val_loss improved from 0.27141 to 0.24079, saving model to step6_4.h5\n",
            "625/625 [==============================] - 120s 192ms/step - loss: 0.2631 - accuracy: 0.9113 - val_loss: 0.2408 - val_accuracy: 0.9189\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9309\n",
            "Epoch 00005: val_loss improved from 0.24079 to 0.23935, saving model to step6_5.h5\n",
            "625/625 [==============================] - 124s 198ms/step - loss: 0.2103 - accuracy: 0.9309 - val_loss: 0.2393 - val_accuracy: 0.9215\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9432\n",
            "Epoch 00006: val_loss improved from 0.23935 to 0.23335, saving model to step6_6.h5\n",
            "625/625 [==============================] - 121s 193ms/step - loss: 0.1711 - accuracy: 0.9432 - val_loss: 0.2333 - val_accuracy: 0.9250\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9524\n",
            "Epoch 00007: val_loss improved from 0.23335 to 0.22620, saving model to step6_7.h5\n",
            "625/625 [==============================] - 120s 192ms/step - loss: 0.1429 - accuracy: 0.9524 - val_loss: 0.2262 - val_accuracy: 0.9273\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9613\n",
            "Epoch 00008: val_loss did not improve from 0.22620\n",
            "625/625 [==============================] - 119s 190ms/step - loss: 0.1181 - accuracy: 0.9613 - val_loss: 0.2320 - val_accuracy: 0.9270\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9668\n",
            "Epoch 00009: val_loss did not improve from 0.22620\n",
            "625/625 [==============================] - 118s 189ms/step - loss: 0.1064 - accuracy: 0.9668 - val_loss: 0.2295 - val_accuracy: 0.9283\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9690\n",
            "Epoch 00010: val_loss did not improve from 0.22620\n",
            "625/625 [==============================] - 118s 189ms/step - loss: 0.0940 - accuracy: 0.9690 - val_loss: 0.2303 - val_accuracy: 0.9297\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9708\n",
            "Epoch 00011: val_loss did not improve from 0.22620\n",
            "625/625 [==============================] - 118s 189ms/step - loss: 0.0863 - accuracy: 0.9708 - val_loss: 0.2303 - val_accuracy: 0.9296\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9725\n",
            "Epoch 00012: val_loss did not improve from 0.22620\n",
            "625/625 [==============================] - 118s 189ms/step - loss: 0.0839 - accuracy: 0.9725 - val_loss: 0.2301 - val_accuracy: 0.9293\n",
            "Epoch 00012: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayrfnWKrBk3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "09d43671-7673-44a7-f9b0-ffbc16840cc5"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig = plt.subplot(1,2,1)\n",
        "plt.plot(history.epoch, history.history['loss'], '-', label='loss')\n",
        "plt.plot(history.epoch, history.history['val_loss'], '--', label='val_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "fig = plt.subplot(1,2,2)\n",
        "plt.plot(history.epoch, history.history['accuracy'], '-', label='accuracy')\n",
        "plt.plot(history.epoch, history.history['val_accuracy'], '--', label='val_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcc96d79f10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqb0x7qSQg2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2098b2-ff72-4c3c-e5f1-d0092807033a"
      },
      "source": [
        "path_to_best_model = \"/content/step6_7.h5\"\n",
        "best_model = tf.keras.models.load_model(path_to_best_model)\n",
        "best_model.evaluate(test_ds, verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 - 9s - loss: 0.3046 - accuracy: 0.9020 - 9s/epoch - 59ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3046385943889618, 0.9020000100135803]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4UWLvcgvAegV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}