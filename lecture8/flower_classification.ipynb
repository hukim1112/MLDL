{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hukim1112/MLDL/blob/master/lecture8/flower_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoQQiZDB6URn"
      },
      "source": [
        "## 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vhAMaIOBIee"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnp9Z2sT5dWj"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO0InzL66URu"
      },
      "source": [
        "### 꽃 데이터세트 다운로드하기\n",
        "\n",
        "이 튜토리얼에서는 수천 장의 꽃 사진 데이터세트를 사용합니다. 꽃 데이터세트에는 클래스당 하나씩 5개의 하위 디렉토리가 있습니다.\n",
        "\n",
        "```\n",
        "flowers_photos/\n",
        "  daisy/\n",
        "  dandelion/\n",
        "  roses/\n",
        "  sunflowers/\n",
        "  tulips/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju2yXtdV5YaT"
      },
      "source": [
        "참고: 모든 이미지에는 CC-BY 라이선스가 있으며 크리에이터는 LICENSE.txt 파일에 나열됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN-Pc6Zd6awg"
      },
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
        "                                   fname='flower_photos', \n",
        "                                   untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFkFK74oO--g"
      },
      "source": [
        "다운로드한 후 (218MB), 이제 꽃 사진의 사본을 사용할 수 있습니다. 총 3670개의 이미지가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhewYCxhXQBX"
      },
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXvLTtgjEqop"
      },
      "source": [
        "# 저장된 경로\n",
        "data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pshwVz_PEpIx"
      },
      "source": [
        "# 리눅스 명령어를 통해 content 폴더 아래로 복사\n",
        "!cp -r /root/.keras/datasets/flower_photos /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUFusk44d9GW"
      },
      "source": [
        "각 디렉토리에는 해당 유형의 꽃 이미지가 포함되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crs7ZjEp60Ot"
      },
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV9PtjdKKWyI"
      },
      "source": [
        "sunflowers = list(data_dir.glob('sunflowers/*'))\n",
        "PIL.Image.open(str(sunflowers[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3EddMWdDMLR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHbLeaSSDMLR"
      },
      "source": [
        "# tf.data로 이미지 파일로부터 파이프라인 만들기\n",
        "보다 세밀한 제어를 위해 `tf.data`을 사용하여 자체 입력 파이프라인을 작성할수 있습니다. 이 섹션에서는 이전에 다운로드한 zip 파일 경로부터 시작하여 이를 수행하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLKfc1bnDMLR"
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
        "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
        "\n",
        "#data_dir의 하위 폴더 및 파일은 다음과 같습니다.\n",
        "print(os.listdir(data_dir))\n",
        "#파일의 트리 구조를 사용하여 `class_names` 목록을 리스트로 만들 수 있습니다.\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jdBkyo2DMLS"
      },
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiptrWmAlmAa"
      },
      "source": [
        "데이터세트를 훈련 및 검증으로 분할합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWHNPzXclpVr"
      },
      "source": [
        "val_size = int(image_count * 0.1)\n",
        "test_size = int(image_count * 0.1)\n",
        "\n",
        "val_ds = list_ds.take(val_size) #val size만큼 취하고,\n",
        "train_ds = list_ds.skip(val_size) #나머지를 train dataset으로..\n",
        "test_ds = train_ds.take(test_size) #다시 test size만큼 취하고,\n",
        "train_ds = train_ds.skip(test_size) #나머지를 train dataset으로.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkB-IR4-pS3U"
      },
      "source": [
        "다음과 같이 각 데이터세트의 길이를 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiKQrb9ppS-7"
      },
      "source": [
        "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(val_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(test_ds).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91CPfUUJ_8SZ"
      },
      "source": [
        "파일 경로를 `(img, label)` 쌍으로 변환하는 간단한 함수를 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arSQzIey-4D4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGlq4IP4Aktb"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)\n",
        "\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xhBRgvNqRRe"
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9a5GpsUOBx8"
      },
      "source": [
        "`Dataset.map`을 사용하여 `image, label` 쌍의 데이터세트를 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SDhbo8lOBQv"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7wWwyzvGgxI"
      },
      "source": [
        "data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqFgh5phGfwV"
      },
      "source": [
        "def augment(img, label):\n",
        "    img = tf.image.resize_with_crop_or_pad(img, img_height + 8, img_width + 8) \n",
        "    # Random crop back to the original size\n",
        "    img = tf.image.random_crop(img, size=[img_height, img_width, 3])\n",
        "    img = tf.image.random_brightness(img, 0.15)\n",
        "    img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "    img = tf.image.random_hue(img, 0.5)\n",
        "    img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "    return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF4qp6YAGoHC"
      },
      "source": [
        "train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxrl0lGdnpRz"
      },
      "source": [
        "for image, label in train_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYGCgJuR_9Qp"
      },
      "source": [
        "### 성능을 위한 데이터세트 구성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwZavzgsIytz"
      },
      "source": [
        "이 데이터세트로 모델을 훈련하려면 데이터에 대해 다음이 필요합니다.\n",
        "\n",
        "- 잘 섞는다.\n",
        "- 배치 처리한다.\n",
        "- 가능한 빨리 배치를 사용할 수 있어야 한다.\n",
        "\n",
        "이러한 기능은 `tf.data` API를 사용하여 추가할 수 있습니다. 자세한 내용은 [입력 파이프라인 성능](../../guide/performance/datasets) 가이드를 참조하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZmZJx8ePw_5"
      },
      "source": [
        "batch_size = 32\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45P7OvzRWzOB"
      },
      "source": [
        "### 데이터 시각화하기\n",
        "\n",
        "이 데이터세트를 이전에 작성한 데이터세트와 유사하게 시각화할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN_Dnl72YNIj"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMT8kh_uXPRU"
      },
      "source": [
        "# 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO_SMWyvDMLV"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "num_classes = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm_bi7NKXOzW"
      },
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8XMPc_3HNli"
      },
      "source": [
        "# 더 좋은 성능을 낼 수 있을까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLx922nzHRBZ"
      },
      "source": [
        "# write your codes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn_XpiR0HRyt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}