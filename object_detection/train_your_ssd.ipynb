{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_your_ssd",
      "provenance": [],
      "authorship_tag": "ABX9TyPICeXBImUDaVLhT/6y2OWp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hukim1112/MLDL/blob/master/object_detection/train_your_ssd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDPRwEpfprX3"
      },
      "source": [
        "# SSD 모델 학습\n",
        "\n",
        "SSD는 사전 정의된 cost 함수 대신 복합적인 cost 함수를 사용한다.\n",
        "\n",
        "따라서 학습을 커스터마이징하기 위한 방법인 Customized model.fit 또는 loop training 방법을 사용해 학습한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNcCXufnqjQi"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NWZyCcwp1zI"
      },
      "source": [
        "## 1.데이터 로드\n",
        "\n",
        "https://drive.google.com/drive/folders/1z-FSY3JN-FWBl87XAZyb4m2KcHqJEUTm?usp=sharing\n",
        "\n",
        "Colab 사용 시 GDUT_HWD.json과 images.zip을 Colab repository에 업로드 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_1vIFmyqd7u"
      },
      "source": [
        "#데이터셋 업로드 후 압축 풀 것.\n",
        "!unzip images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhSf-2M_qd9-"
      },
      "source": [
        "image_dir = '/content/images'\n",
        "annotation = '/content/GDUT_HWD.json'\n",
        "\n",
        "#압축\n",
        "img_list = os.listdir(image_dir)\n",
        "img_path = os.path.join(image_dir, img_list[0])\n",
        "img = cv2.imread(img_path)[:,:,::-1]\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moSgCoHVxrud"
      },
      "source": [
        "# 2.데이터 파이프라인\n",
        "\n",
        "anchor.py, box_uitls.py,pycoco.py, losses.py, post_process.py를 colab에 업로드하십시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iPCBkwaqeAT"
      },
      "source": [
        "import data\n",
        "from anchor import generate_default_boxes\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# anchor box 생성\n",
        "anchor_param = {\"ratios\": [[2], [2, 3], [2, 3], [2, 3], [2]],\n",
        "                           \"scales\": [0.1, 0.3, 0.5, 0.7, 0.9, 1.075],\n",
        "                           \"fm_sizes\": [28, 14, 7, 3, 1],\n",
        "                           \"image_size\": 224} #anchor parameters\n",
        "anchors = generate_default_boxes(anchor_param)\n",
        "\n",
        "label_set = [\"head\",\"helmet\"]\n",
        "input_shape = (224,224,3)\n",
        "batch_size = 16\n",
        "shuffle_buffer = 159\n",
        "\n",
        "ds_obj = data.Dataset(COCO, anchors, image_dir, annotation, label_set, input_shape)\n",
        "train_ds, train_length = ds_obj.load_data_generator('train')\n",
        "train_ds = train_ds.shuffle(shuffle_buffer).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHSWQB_CqeCj"
      },
      "source": [
        "for i, (_, imgs, gt_confs, gt_locs) in enumerate(train_ds.take(1)):\n",
        "    print(imgs.shape, gt_confs.shape, gt_locs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96KjKPeGqgfI"
      },
      "source": [
        "## 3.모델 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpmxsKxCz9Rt"
      },
      "source": [
        "이전에 빌드했던 모델을 불러온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-819joRBpisD"
      },
      "source": [
        "# model load\n",
        "path = \"/path/to/your/ssd/model.h5\"\n",
        "path = \"/content/ssd.h5\"\n",
        "model = tf.keras.models.load_model(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egnwpRLw3OHB"
      },
      "source": [
        "# 4.1 customized model.fit\n",
        "\n",
        "모델 학습을 더 자세히 제어하기 위해 model.fit 함수를 커스터마이즈 합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWJY0YrMrHL6"
      },
      "source": [
        "import losses\n",
        "criterion = losses.create_losses(num_classes=3, \n",
        "                                 num_anchors=anchors.shape[0],\n",
        "                                 neg_ratio=3, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz4NC11QnXob"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "class Custom_train(tf.keras.Model):\n",
        "  def train_step(self, data):\n",
        "      _, imgs, gt_confs, gt_locs = data\n",
        "      with tf.GradientTape() as tape:\n",
        "          imgs = preprocess_input(imgs)\n",
        "          confs, locs = self(imgs, training=True)\n",
        "\n",
        "          conf_loss, loc_loss = criterion(\n",
        "              confs, locs, gt_confs, gt_locs)\n",
        "\n",
        "          loss = conf_loss + loc_loss\n",
        "          l2_loss = [tf.nn.l2_loss(t) for t in self.trainable_variables]\n",
        "          l2_loss = self.weight_decay * tf.math.reduce_sum(l2_loss)\n",
        "          loss += l2_loss\n",
        "\n",
        "      # Compute gradients\n",
        "      trainable_vars = self.trainable_variables\n",
        "      gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "      # Update weights\n",
        "      self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "      # Compute our own metrics\n",
        "      loss_tracker.update_state(loss)\n",
        "      return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "      # We list our `Metric` objects here so that `reset_states()` can be\n",
        "      # called automatically at the start of each epoch\n",
        "      # or at the start of `evaluate()`.\n",
        "      # If you don't implement this property, you have to call\n",
        "      # `reset_states()` yourself at the time of your choosing.\n",
        "      return [loss_tracker]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvbJXewwnXqp"
      },
      "source": [
        "custom_model = Custom_train(model.input, model.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw4YvFoxnXtU"
      },
      "source": [
        "learning_rate = 1E-3\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "custom_model.compile(optimizer)\n",
        "custom_model.weight_decay = 5e-5\n",
        "history = custom_model.fit(train_ds, epochs=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mPzBpCmnXv9"
      },
      "source": [
        "model = custom_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd4xIRjRpiw2"
      },
      "source": [
        "plt.plot(history.epoch, history.history['loss'], '-', label='loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5qiFLGgqphZ"
      },
      "source": [
        "# 4.2 트레이닝 루프 방식(optional)\n",
        "\n",
        "학습 알고리즘을 커스터마이즈하는 또 다른 방식인 트레이닝 루프 방식입니다. 트레이닝 루프는 for loop 수준에서 학습 과정을 미세제어할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-4Pu-Drhrc"
      },
      "source": [
        "import losses\n",
        "criterion = losses.create_losses(num_classes=3, \n",
        "                                 num_anchors=anchors.shape[0],\n",
        "                                 neg_ratio=3, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWrn8W0tpiy5"
      },
      "source": [
        "@tf.function\n",
        "def train_step(imgs, gt_confs, gt_locs, model, criterion, optimizer, weight_decay):\n",
        "    with tf.GradientTape() as tape:\n",
        "        confs, locs = model(imgs)\n",
        "\n",
        "        conf_loss, loc_loss = criterion(\n",
        "            confs, locs, gt_confs, gt_locs)\n",
        "\n",
        "        loss = conf_loss + loc_loss\n",
        "        l2_loss = [tf.nn.l2_loss(t) for t in model.trainable_variables]\n",
        "        l2_loss = weight_decay * tf.math.reduce_sum(l2_loss)\n",
        "        loss += l2_loss\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss, conf_loss, loc_loss, l2_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M6-eKsssD0c"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "t_loss = tf.metrics.Mean(name='train_loss')\n",
        "t_conf_loss = tf.metrics.Mean(name='train_conf_loss')\n",
        "t_loc_loss = tf.metrics.Mean(name='train_loc_loss')\n",
        "# v_loss = tf.metrics.Mean(name='val_loss')\n",
        "# v_conf_loss = tf.metrics.Mean(name='val_conf_loss')\n",
        "# v_loc_loss = tf.metrics.Mean(name='val_loc_loss')\n",
        "\n",
        "EPOCH = 50\n",
        "START = 0\n",
        "learning_rate = 1E-3\n",
        "weight_decay = 5e-5\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "for epoch in range(START+1, START+EPOCH+1):\n",
        "    for i, (_, imgs, gt_confs, gt_locs) in enumerate(train_ds):\n",
        "        imgs = preprocess_input(imgs)\n",
        "        loss, conf_loss, loc_loss, l2_loss = train_step(\n",
        "            imgs, gt_confs, gt_locs, model, criterion, optimizer, weight_decay)\n",
        "        t_loss(loss)\n",
        "        t_conf_loss(conf_loss)\n",
        "        t_loc_loss(loc_loss)\n",
        "        print(\"Epoch {} iteration {} loss : {}\".format(epoch, i, t_loss.result()))\n",
        "    \n",
        "    '''\n",
        "    you can add the code of validation test, but we don't have it now.\n",
        "    for i, (_, imgs, gt_confs, gt_locs) in enumerate(val_generator):\n",
        "        imgs = preprocess_input(imgs)\n",
        "        val_confs, val_locs = model(imgs)\n",
        "        val_conf_loss, val_loc_loss = criterion(val_confs, val_locs, gt_confs, gt_locs)\n",
        "        v_loss(val_conf_loss+val_loc_loss)\n",
        "        v_conf_loss(val_conf_loss)\n",
        "        v_loc_loss(val_loc_loss)\n",
        "    '''\n",
        "    print(\"Epoch:{}, loss:{}\".format(epoch, t_loss.result()))\n",
        "    t_loss.reset_states()\n",
        "    t_conf_loss.reset_states()\n",
        "    t_loc_loss.reset_states()\n",
        "    #v_loss.reset_states()()))\n",
        "    #v_conf_loss.reset_states()\n",
        "    #v_loc_loss.reset_states()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8arcpy6sKX9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiNFoxLVsLL4"
      },
      "source": [
        "# 5.학습데이터에 대해 모델 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnMG1kiVtGPI"
      },
      "source": [
        "예측 결과를 NMS으로 처리하기 위한 post_process를 import 하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1AJUIBttkVn"
      },
      "source": [
        "import post_process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZEgyU8isKZ-"
      },
      "source": [
        "img_list = os.listdir(image_dir)\n",
        "img_path = os.path.join(image_dir, img_list[0])\n",
        "img = cv2.imread(img_path)[:,:,::-1]\n",
        "plt.imshow(img)\n",
        "\n",
        "H,W = img.shape[:2]\n",
        "resized_img = cv2.resize(img, (224,224)) #resize\n",
        "processed_img = preprocess_input(resized_img[tf.newaxis]) #정규화\n",
        "\n",
        "confs, locs = model(processed_img) #예측\n",
        "num_classes = 3\n",
        "results = post_process.predict(confs, locs, anchors, num_classes, conf_thresh=0.5) \n",
        "# 결과에 Non maximum suppression 적용\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05BxnWPFsKcx"
      },
      "source": [
        "drawn_img = img.copy()\n",
        "for box in results[0][0]:\n",
        "    x1, y1, x2, y2 = box\n",
        "    x1 = int(x1*W)\n",
        "    x2 = int(x2*W)\n",
        "    y1 = int(y1*H)\n",
        "    y2 = int(y2*H)\n",
        "    print(x1, y1, x2, y2)\n",
        "    drawn_img = cv2.rectangle(drawn_img, (x1,y1), (x2,y2), (255,0,0), 3)\n",
        "plt.imshow(drawn_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF0X8WLXxp8f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}