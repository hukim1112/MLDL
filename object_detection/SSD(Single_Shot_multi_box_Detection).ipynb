{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxtviV2E7zlN"
   },
   "source": [
    "# 데이터셋 다운로드\n",
    "\n",
    "### https://drive.google.com/drive/folders/1z-FSY3JN-FWBl87XAZyb4m2KcHqJEUTm?usp=sharing\n",
    "\n",
    "### Colab 사용 시 Colab repository에 업로드 할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Backbone 신경망의 전이학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 = MobileNetV2(input_shape=(224,224,3), weights=\"imagenet\", include_top=False)\n",
    "tf.keras.utils.plot_model(mobilenet_v2, show_shapes=True, expand_nested=True)\n",
    "\n",
    "start = mobilenet_v2.get_layer(\"input_1\").input\n",
    "end = mobilenet_v2.get_layer(\"block_5_add\").output\n",
    "backbone = tf.keras.Model(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Neck 신경망 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pF1FZSd7zlQ"
   },
   "outputs": [],
   "source": [
    "#input shape (BN, H, W, C)\n",
    "\n",
    "block1 = tf.keras.Sequential([tf.keras.layers.Conv2D(256, 1, padding='same'),\n",
    "                     tf.keras.layers.BatchNormalization(),\n",
    "                     tf.keras.layers.ReLU(),\n",
    "\n",
    "                     tf.keras.layers.DepthwiseConv2D(3, strides=(2,2), padding='same'),\n",
    "                     tf.keras.layers.BatchNormalization(),\n",
    "                     tf.keras.layers.ReLU(),\n",
    "\n",
    "                     tf.keras.layers.Conv2D(256, 1, padding='same'),\n",
    "                     tf.keras.layers.BatchNormalization(),\n",
    "                     tf.keras.layers.ReLU()])\n",
    "                    # **** conv => depthwise-conv => conv ****\n",
    "                    #output1 [BN,H/2,W/2,512]\n",
    "\n",
    "block2 = tf.keras.Sequential([tf.keras.layers.Conv2D(256, 1, padding='same'),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU(),\n",
    "\n",
    "                    tf.keras.layers.DepthwiseConv2D(3, strides=(2,2), padding='same'),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU(),\n",
    "\n",
    "                    tf.keras.layers.Conv2D(256, 1, padding='same'),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU(),])\n",
    "                    # **** conv => depthwise-conv => conv ****\n",
    "                    #output1 [BN,H/4,W/4,512]\n",
    "        \n",
    "block3 = tf.keras.Sequential([tf.keras.layers.Conv2D(256, 1, padding='same'),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU(),\n",
    "\n",
    "                    tf.keras.layers.DepthwiseConv2D(3, strides=(2,2)),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU(),\n",
    "\n",
    "                    tf.keras.layers.Conv2D(256, 1, padding='same'),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU()])\n",
    "                    # **** conv => depthwise-conv => conv ****\n",
    "                    #output1 [BN,H/8,W/8,512]\n",
    "        \n",
    "block4 = tf.keras.Sequential([tf.keras.layers.Conv2D(256, 1, padding='same'),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU(),\n",
    "\n",
    "                    tf.keras.layers.DepthwiseConv2D(3, strides=(2,2)),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU(),\n",
    "\n",
    "                    tf.keras.layers.Conv2D(256, 1, padding='same'),\n",
    "                    tf.keras.layers.BatchNormalization(),\n",
    "                    tf.keras.layers.ReLU()])\n",
    "                    # **** conv => depthwise-conv => conv ****\n",
    "                    #output1 [BN,H/16,W/16,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfnkxN_47zlU",
    "outputId": "c4dc0223-748c-456b-ea21-f60003b5e400"
   },
   "outputs": [],
   "source": [
    "input_layer = tf.keras.Input(shape=(224,224,3))\n",
    "x = backbone(input_layer)\n",
    "y1 = block1(x)\n",
    "y2 = block2(y1)\n",
    "y3 = block3(y2)\n",
    "y4 = block4(y3)\n",
    "\n",
    "print(\"첫 번째 feature map : \", x.shape,\\\n",
    "      \"두 번째 feature map : \", y1.shape,\\\n",
    "      \"세 번째 feature map : \", y2.shape,\\\n",
    "      \"네 번쨰 feature map : \",y3.shape,\\\n",
    "      \"다섯번째 feature map : \",y4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMJtslmp7zlU"
   },
   "source": [
    "# C. head(classification, regression) 신경망 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iH5GqkWL7zlU",
    "outputId": "0f0fcd97-c4de-444b-b278-55e1c59dde62"
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "#classification head\n",
    "confs = []\n",
    "conf = layers.Conv2D(4 * num_classes, kernel_size=3, padding='same')(x)\n",
    "conf = tf.reshape(conf, [-1, 28*28*4,num_classes])\n",
    "confs.append(conf)\n",
    "conf = layers.Conv2D(6 * num_classes, kernel_size=3, padding='same')(y1)\n",
    "conf = tf.reshape(conf, [-1, 14*14*6,num_classes])\n",
    "confs.append(conf)\n",
    "conf = layers.Conv2D(6 * num_classes, kernel_size=3, padding='same')(y2)\n",
    "conf = tf.reshape(conf, [-1, 7*7*6,num_classes])\n",
    "confs.append(conf)\n",
    "conf = layers.Conv2D(6 * num_classes, kernel_size=3, padding='same')(y3)\n",
    "conf = tf.reshape(conf, [-1, 3*3*6,num_classes])\n",
    "confs.append(conf)\n",
    "conf = layers.Conv2D(4 * num_classes, kernel_size=1)(y4)\n",
    "conf = tf.reshape(conf, [-1, 1*1*4,num_classes])\n",
    "confs.append(conf)\n",
    "\n",
    "\n",
    "#regression head\n",
    "locs = []\n",
    "loc = layers.Conv2D(4 * 4, kernel_size=3, padding='same')(x)\n",
    "loc = tf.reshape(loc, [-1, 28*28*4,4])\n",
    "print(loc.shape)\n",
    "locs.append(loc)\n",
    "loc = layers.Conv2D(6 * 4, kernel_size=3, padding='same')(y1)\n",
    "loc = tf.reshape(loc, [-1, 14*14*6,4])\n",
    "print(loc.shape)\n",
    "locs.append(loc)\n",
    "loc = layers.Conv2D(6 * 4, kernel_size=3, padding='same')(y2)\n",
    "loc = tf.reshape(loc, [-1, 7*7*6,4])\n",
    "print(loc.shape)\n",
    "locs.append(loc)\n",
    "loc = layers.Conv2D(6 * 4, kernel_size=3, padding='same')(y3)\n",
    "loc = tf.reshape(loc, [-1, 3*3*6,4])\n",
    "print(loc.shape)\n",
    "locs.append(loc)\n",
    "loc = layers.Conv2D(4 * 4, kernel_size=1)(y4)\n",
    "loc = tf.reshape(loc, [-1, 1*1*4,4])\n",
    "print(loc.shape)\n",
    "locs.append(loc)\n",
    "\n",
    "confs = tf.concat(confs, axis=-2)\n",
    "locs = tf.concat(locs, axis=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy13WwZJ7zlV"
   },
   "source": [
    "# D. 최종 모델 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGBdPvfM7zlV"
   },
   "outputs": [],
   "source": [
    "mobilenet_ssd = tf.keras.Model(inputs=[input_layer], outputs=[confs,locs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Zwa6DJZb7zlW",
    "outputId": "f8fd7c56-f4b3-4c01-d15c-3c83ba977347"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(mobilenet_ssd, show_shapes=True, expand_nested=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vO_LutJq7zlW",
    "outputId": "0409e0b7-1222-4b19-b102-56cc5f0d5e9a"
   },
   "outputs": [],
   "source": [
    "mobilenet_ssd(np.ones([1, 224, 224, 3], np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hH-YoQeJ9GIO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avt0Gafc7zlW"
   },
   "source": [
    "# SSD 유틸러티 모듈 다운로드 & 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFiCCrsM9FkO"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/hukim1112/MLDL.git\n",
    "import sys\n",
    "sys.path.append(\"/content/MLDL/object_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmFS8bjo9w5_",
    "outputId": "6ce3dfbd-101f-40fd-e201-581901561229"
   },
   "outputs": [],
   "source": [
    "#데이터셋 업로드 후 압축 풀 것.\n",
    "!unzip images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "ria43EPI-P3g",
    "outputId": "0c18751c-0d05-45fe-f7fd-6bb9961564c4"
   },
   "outputs": [],
   "source": [
    "image_dir = '/content/images'\n",
    "annotation = '/content/GDUT_HWD.json'\n",
    "\n",
    "#압축\n",
    "img_list = os.listdir(image_dir)\n",
    "img_path = os.path.join(image_dir, img_list[0])\n",
    "img = cv2.imread(img_path)[:,:,::-1]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UF5rF5pH-Ru0"
   },
   "source": [
    "# 학습 configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbyotOcR7zlX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import anchor, losses, manage_checkpoint, coco, post_process\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQfM1T-07zlX"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"label_set\" : [\"head\",\"helmet\"], # 분류할 오브젝트 집합\n",
    "    \"input_shape\" : [224, 224, 3], #모델입력영상 크기\n",
    "    \"anchor_param\" : {\"ratios\": [[2], [2, 3], [2, 3], [2, 3], [2]],\n",
    "                           \"scales\": [0.1, 0.3, 0.5, 0.7, 0.9, 1.075],\n",
    "                           \"fm_sizes\": [28, 14, 7, 3, 1],\n",
    "                           \"image_size\": 224}, #anchor parameters\n",
    "    \"train\" :\n",
    "    {\n",
    "        \"num_examples\" : -1,\n",
    "        \"batch_size\" : 8,\n",
    "        \"neg_ratio\" : 3,\n",
    "        \"initial_lr\" : 1e-3,\n",
    "        \"momentum\" : 0.9,\n",
    "        \"weight_decay\" : 5e-5,\n",
    "    },\n",
    "    \"val\":\n",
    "    {\n",
    "        \"num_examples\" : -1,\n",
    "        \"batch_size\" : 8\n",
    "    },\n",
    "    \"test\":\n",
    "    {\n",
    "        \"num_examples\" : -1,\n",
    "        \"batch_size\" : 1\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_ljWBNB-LJp"
   },
   "source": [
    "# 데이터셋 오브젝트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2SB5jDz7zlY"
   },
   "outputs": [],
   "source": [
    "ds_obj = coco.Dataset(image_dir, annotation, config, COCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BffnC9B7zlY",
    "outputId": "9609c44e-39c5-49bd-ef15-167aefe425b6"
   },
   "outputs": [],
   "source": [
    "train_ds, train_length = ds_obj.load_data_generator('train')\n",
    "print(\"Dataset length : \", train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZWJtQsw7zlZ",
    "outputId": "92a4142e-c177-4259-c695-6ca967fde431"
   },
   "outputs": [],
   "source": [
    "for i, (_, imgs, gt_confs, gt_locs) in enumerate(train_ds.take(1)):\n",
    "    print(imgs.shape, gt_confs.shape, gt_locs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzOcvIvg7zlZ"
   },
   "outputs": [],
   "source": [
    "batch_size = config[\"train\"][\"batch_size\"]\n",
    "shuffle_buffer = 159\n",
    "\n",
    "train_ds = train_ds.shuffle(shuffle_buffer).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADWhBmCV7zlZ",
    "outputId": "a42ad88a-d0d0-4c82-b7a4-a140d1f0cb1a"
   },
   "outputs": [],
   "source": [
    "for i, (_, imgs, gt_confs, gt_locs) in enumerate(train_ds.take(1)):\n",
    "    print(imgs.shape, gt_confs.shape, gt_locs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGolzmQR7zla"
   },
   "source": [
    "# Anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cG5fL1jn7zla"
   },
   "outputs": [],
   "source": [
    "default_boxes = anchor.generate_default_boxes(config[\"anchor_param\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVgIPHy97zla",
    "outputId": "8943bd45-4d21-4d82-e8dc-80c33c323bbd"
   },
   "outputs": [],
   "source": [
    "default_boxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAhJ8cP27zla"
   },
   "source": [
    "# Train a mobilenet-SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRu4Jrsy7zla"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(imgs, gt_confs, gt_locs, model, criterion, optimizer, config):\n",
    "    with tf.GradientTape() as tape:\n",
    "        confs, locs = model(imgs)\n",
    "\n",
    "        conf_loss, loc_loss = criterion(\n",
    "            confs, locs, gt_confs, gt_locs)\n",
    "\n",
    "        loss = conf_loss + loc_loss\n",
    "        l2_loss = [tf.nn.l2_loss(t) for t in model.trainable_variables]\n",
    "        l2_loss = config['train']['weight_decay'] * tf.math.reduce_sum(l2_loss)\n",
    "        loss += l2_loss\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, conf_loss, loc_loss, l2_loss\n",
    "\n",
    "criterion = losses.create_losses(config['train']['neg_ratio'], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Jgq9A-k7zlb",
    "outputId": "e90317d4-447c-4240-af7b-850cc6dbfc5a"
   },
   "outputs": [],
   "source": [
    "t_loss = tf.metrics.Mean(name='train_loss')\n",
    "t_conf_loss = tf.metrics.Mean(name='train_conf_loss')\n",
    "t_loc_loss = tf.metrics.Mean(name='train_loc_loss')\n",
    "# v_loss = tf.metrics.Mean(name='val_loss')\n",
    "# v_conf_loss = tf.metrics.Mean(name='val_conf_loss')\n",
    "# v_loc_loss = tf.metrics.Mean(name='val_loc_loss')\n",
    "\n",
    "learning_rate = 1E-3\n",
    "EPOCH = 50\n",
    "START = 0\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "for epoch in range(START+1, START+EPOCH+1):\n",
    "    for i, (_, imgs, gt_confs, gt_locs) in enumerate(train_ds):\n",
    "        imgs = preprocess_input(imgs)\n",
    "        loss, conf_loss, loc_loss, l2_loss = train_step(\n",
    "            imgs, gt_confs, gt_locs, mobilenet_ssd, criterion, optimizer, config)\n",
    "        t_loss(loss)\n",
    "        t_conf_loss(conf_loss)\n",
    "        t_loc_loss(loc_loss)\n",
    "        \n",
    "        print(\"Epoch {} iteration {} loss : {}\".format(epoch, i, t_loss.result()))\n",
    "    \n",
    "    '''\n",
    "    you can add the code of validation test, but we don't have it now.\n",
    "    for i, (_, imgs, gt_confs, gt_locs) in enumerate(val_generator):\n",
    "        imgs = preprocess_input(imgs)\n",
    "        val_confs, val_locs = model(imgs)\n",
    "        val_conf_loss, val_loc_loss = criterion(val_confs, val_locs, gt_confs, gt_locs)\n",
    "        v_loss(val_conf_loss+val_loc_loss)\n",
    "        v_conf_loss(val_conf_loss)\n",
    "        v_loc_loss(val_loc_loss)\n",
    "    '''\n",
    "    print(\"Epoch:{}, loss:{}\".format(epoch, t_loss.result()))\n",
    "    t_loss.reset_states()\n",
    "    t_conf_loss.reset_states()\n",
    "    t_loc_loss.reset_states()\n",
    "    #v_loss.reset_states()()))\n",
    "    #v_conf_loss.reset_states()\n",
    "    #v_loc_loss.reset_states()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCIPtSEA7zlb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04DT2gFx7zlc"
   },
   "source": [
    "# 간단한 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "5Zp0J4Td7zlc",
    "outputId": "6240f8c1-369c-45ad-e500-4a0460917cad"
   },
   "outputs": [],
   "source": [
    "img_list = os.listdir(image_dir)\n",
    "img_path = os.path.join(image_dir, img_list[0])\n",
    "img = cv2.imread(img_path)[:,:,::-1]\n",
    "plt.imshow(img)\n",
    "\n",
    "H,W = img.shape[:2]\n",
    "resized_img = cv2.resize(img, (224,224)) #resize\n",
    "processed_img = preprocess_input(resized_img[tf.newaxis]) #정규화\n",
    "\n",
    "\n",
    "confs, locs = mobilenet_ssd(processed_img) #예측\n",
    "results = post_process.predict(confs, locs, default_boxes, num_classes, conf_thresh=0.5) \n",
    "# 결과에 Non maximum suppression 적용\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "MS6VC5E_7zlc",
    "outputId": "529761aa-1ecc-46c0-d1fc-85325b3d7f5a"
   },
   "outputs": [],
   "source": [
    "drawn_img = img.copy()\n",
    "for box in results[0][0]:\n",
    "    x1, y1, x2, y2 = box\n",
    "    x1 = int(x1*W)\n",
    "    x2 = int(x2*W)\n",
    "    y1 = int(y1*H)\n",
    "    y2 = int(y2*H)\n",
    "    print(x1, y1, x2, y2)\n",
    "    drawn_img = cv2.rectangle(drawn_img, (x1,y1), (x2,y2), (255,0,0), 3)\n",
    "plt.imshow(drawn_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZe9RqmP7zlc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoYpj1vy7zlc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "SSD(Single Shot multi-box Detection).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
