{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json, os, sys, time\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import anchor, losses, manage_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"exp_desc\" : \"perfection\", #실험명\n",
    "    \"sub_desc\" : \"exp1\", #하위실험명\n",
    "    \"image_dir\" : \"/home/dan/Desktop/images\", #이미지경로\n",
    "    \"coco_api\" : \"/home/dan/prj/PythonAPI\",\n",
    "    \"annotation_dir\" : \"/home/dan/Desktop/annotations\", #어노테이션 경로\n",
    "    \"label_set\" : [\"head\",\"helmet\"], # 분류할 오브젝트 집합\n",
    "    \"input_shape\" : [300, 300, 3], #모델입력영상 크기\n",
    "    \"arch\" : \"ssd96_v1\",\n",
    "    \"backbone\" : \"mobilenet\",\n",
    "    \"anchor_param\" : {\"ratios\": [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "                           \"scales\": [0.1, 0.2, 0.375, 0.55, 0.725, 0.9, 1.075],\n",
    "                           \"fm_sizes\": [38, 19, 10, 5, 3, 1],\n",
    "                           \"image_size\": 300}, #anchor parameters\n",
    "    \"ckpt\":\n",
    "    {\n",
    "        \"save_type\" : \"best\",\n",
    "        \"max_to_keep\" : 10,\n",
    "        \"pretrained_type\" : \"init\",\n",
    "        \"model_path\" : None\n",
    "    },\n",
    "    \"inference_mode\" : \"train\", # train or mAP\n",
    "    \"train\" :\n",
    "    {\n",
    "        \"num_examples\" : -1,\n",
    "        \"batch_size\" : 16,\n",
    "        \"augmentation\" : True,\n",
    "        \"random_crop_rate\" : 0.3,\n",
    "        \"neg_ratio\" : 3,\n",
    "        \"initial_lr\" : 1e-3,\n",
    "        \"momentum\" : 0.9,\n",
    "        \"weight_decay\" : 5e-5,\n",
    "        \"num_epochs\" : 300\n",
    "    },\n",
    "    \"val\":\n",
    "    {\n",
    "        \"num_examples\" : -1,\n",
    "        \"batch_size\" : 64\n",
    "    },\n",
    "    \"test\":\n",
    "    {\n",
    "        \"num_examples\" : -1,\n",
    "        \"batch_size\" : 1\n",
    "    }\n",
    "\n",
    "}\n",
    "num_classes = len(config['label_set'])\n",
    "ckpt_dir = os.path.join('ckpts', 'perfection', 'exp1')\n",
    "log_dir = os.path.join('logs', 'perfection', 'exp1')\n",
    "# if os.path.isdir(ckpt_dir):\n",
    "#     raise ValueError(\"checkpoint directory exists. checkout your experiment name in configure file.\")\n",
    "# if os.path.isdir(log_dir):\n",
    "#     raise ValueError(\"log directory exists. checkout your experiment name in configure file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coco import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(config['coco_api'])\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "ds_obj = Dataset(config, COCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "batch_generator, train_length = ds_obj.load_data_generator('train', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 300, 300, 3) (16, 8732) (16, 8732, 4)\n"
     ]
    }
   ],
   "source": [
    "for i, (_, imgs, gt_confs, gt_locs) in enumerate(batch_generator.take(1)):\n",
    "    print(imgs.shape, gt_confs.shape, gt_locs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"ssd300-mobilenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       [(None, 38, 38, 192) 616256      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, None, None, 5 569344      functional_1[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, None, None, 5 536576      sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, None, None, 5 536576      sequential_4[0][0]               \n",
      "                                                                 sequential_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 38, 38, 12)   20748       functional_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 19, 19, 18)   93330       functional_1[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 10, 10, 18)   82962       sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 5, 5, 18)     82962       sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 3, 3, 18)     82962       sequential_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 1, 1, 12)     6156        sequential_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 38, 38, 16)   27664       functional_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 19, 19, 24)   124440      functional_1[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 10, 10, 24)   110616      sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 5, 5, 24)     110616      sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 3, 3, 24)     110616      sequential_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 1, 1, 16)     8208        sequential_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_12 (TensorF (None, 5776, 3)      0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_13 (TensorF (None, 2166, 3)      0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_14 (TensorF (None, 600, 3)       0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_15 (TensorF (None, 150, 3)       0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_16 (TensorF (None, 36, 3)        0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_17 (TensorF (None, 4, 3)         0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_18 (TensorF (None, 5776, 4)      0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_19 (TensorF (None, 2166, 4)      0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_20 (TensorF (None, 600, 4)       0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_21 (TensorF (None, 150, 4)       0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_22 (TensorF (None, 36, 4)        0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_23 (TensorF (None, 4, 4)         0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo (None, 8732, 3)      0           tf_op_layer_Reshape_12[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_13[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_14[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_15[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_16[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo (None, 8732, 4)      0           tf_op_layer_Reshape_18[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_19[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_20[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_21[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_22[0][0]     \n",
      "                                                                 tf_op_layer_Reshape_23[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 3,120,032\n",
      "Trainable params: 2,494,560\n",
      "Non-trainable params: 625,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[1].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(imgs, gt_confs, gt_locs, ssd, criterion, optimizer, config):\n",
    "    with tf.GradientTape() as tape:\n",
    "        confs, locs = ssd(imgs)\n",
    "\n",
    "        conf_loss, loc_loss = criterion(\n",
    "            confs, locs, gt_confs, gt_locs)\n",
    "\n",
    "        loss = conf_loss + loc_loss\n",
    "        l2_loss = [tf.nn.l2_loss(t) for t in ssd.trainable_variables]\n",
    "        l2_loss = config['train']['weight_decay'] * tf.math.reduce_sum(l2_loss)\n",
    "        loss += l2_loss\n",
    "\n",
    "    gradients = tape.gradient(loss, ssd.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, ssd.trainable_variables))\n",
    "\n",
    "    return loss, conf_loss, loc_loss, l2_loss\n",
    "\n",
    "criterion = losses.create_losses(config['train']['neg_ratio'], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "t_loss = tf.metrics.Mean(name='train_loss')\n",
    "t_conf_loss = tf.metrics.Mean(name='train_conf_loss')\n",
    "t_loc_loss = tf.metrics.Mean(name='train_loc_loss')\n",
    "# v_loss = tf.metrics.Mean(name='val_loss')\n",
    "# v_conf_loss = tf.metrics.Mean(name='val_conf_loss')\n",
    "# v_loc_loss = tf.metrics.Mean(name='val_loc_loss')\n",
    "\n",
    "learning_rate = 1E-3\n",
    "EPOCH = 50\n",
    "START = 0\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "for epoch in range(START+1, START+EPOCH+1):\n",
    "    start = time.time()\n",
    "    for i, (_, imgs, gt_confs, gt_locs) in enumerate(batch_generator):\n",
    "        imgs = preprocess_input(imgs)\n",
    "        loss, conf_loss, loc_loss, l2_loss = train_step(\n",
    "            imgs, gt_confs, gt_locs, model, criterion, optimizer, config)\n",
    "        t_loss(loss)\n",
    "        t_conf_loss(conf_loss)\n",
    "        t_loc_loss(loc_loss)\n",
    "        \n",
    "        print(\"Epoch {} iteration {} loss : {}\".format(epoch, i, t_loss.result()))\n",
    "    \n",
    "    '''\n",
    "    you can add the validation part\n",
    "    \n",
    "    for i, (_, imgs, gt_confs, gt_locs) in enumerate(val_generator):\n",
    "        imgs = preprocess_input(imgs)\n",
    "        val_confs, val_locs = model(imgs)\n",
    "        val_conf_loss, val_loc_loss = criterion(val_confs, val_locs, gt_confs, gt_locs)\n",
    "        v_loss(val_conf_loss+val_loc_loss)\n",
    "        v_conf_loss(val_conf_loss)\n",
    "        v_loc_loss(val_loc_loss)\n",
    "    '''\n",
    "    # Save checkpoint with a strategy.\n",
    "    if epoch%10 == 0:\n",
    "        model.save(\"{}.h5\".format(epoch))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('train_loss', t_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('train_conf_loss', t_conf_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('train_loc_loss', t_loc_loss.result(), step=epoch)\n",
    "        #tf.summary.scalar('val_loss', v_loss.result(), step=epoch)\n",
    "        #tf.summary.scalar('val_conf_loss', v_conf_loss.result(), step=epoch)\n",
    "        #tf.summary.scalar('val_loc_loss', v_loc_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('learning_rate', learning_rate, step=epoch)\n",
    "        \n",
    "    t_loss.reset_states()\n",
    "    t_conf_loss.reset_states()\n",
    "    t_loc_loss.reset_states()\n",
    "    #v_loss.reset_states()\n",
    "    #v_conf_loss.reset_states()\n",
    "    #v_loc_loss.reset_states()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
